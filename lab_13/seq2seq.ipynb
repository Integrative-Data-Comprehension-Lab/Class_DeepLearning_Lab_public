{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchtext\n",
    "import torchtext.datasets\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from helpers import evaluate_one_epoch, plot_token_frequency_histogram, plot_token_count_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” IMDB(Large Movie Review Dataset) ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì˜í™” ë¦¬ë·°ì˜ ê°ì •ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„°ì…‹ì€ ì´ 5ë§Œê°œì˜ ì˜í™” ë¦¬ë·°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë¦¬ë·°ì—ëŠ” ê¸ì •(positive) ë˜ëŠ” ë¶€ì •(negative) ê°ì •ìœ¼ë¡œ ë ˆì´ë¸”ì´ ì§€ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € IMDB ë°ì´í„°ì…‹ì„ ê°„ë‹¨íˆ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = torchtext.datasets.IMDB(root = \"/datasets/NLP\")\n",
    "\n",
    "for label, text in train_iter:\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Text :\", text, \"\\n\")\n",
    "    print(\"Label:\", label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtext` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš© ì‹œ ë°œìƒí•˜ëŠ” deprecation warningëŠ” ëª¨ë‘ ë¬´ì‹œí•´ë„ ê´œì°®ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- Text: ì˜í™” ë¦¬ë·°ê°€ ë¬¸ìì—´ í˜•íƒœë¡œ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- Label: ë¦¬ë·°ì˜ ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜ê°’ì…ë‹ˆë‹¤\n",
    "   - 1 : Negative reviews (ë¶€ì •ì ì¸ ë¦¬ë·°)\n",
    "   - 2 : Positive reviews (ê¸ì •ì ì¸ ë¦¬ë·°)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Word-level tokenizer\n",
    "\n",
    "ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing, NLP)ë¥¼ ìœ„í•œ ì²«ë²ˆì§¸ ê³¼ì •ì€ í…ìŠ¤íŠ¸ ë°ì´í„°(Corpus)ë¥¼ ì¼ì •í•œ ë‹¨ìœ„ì¸ <b>í† í°(Token)</b>ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤\n",
    "\n",
    "### í† í°(Token) ì´ë€?\n",
    "\n",
    "í† í°ì€ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì •ì˜í•œ ìµœì†Œ ë‹¨ìœ„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    " - ì‚¬ìš©ìì— ë”°ë¼ ë‹¨ì–´(word), ê¸€ì(character), ë˜ëŠ” ì„œë¸Œì›Œë“œ(subword) ë“±ìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆìœ¼ë©°, ì–´ë–¤ ë‹¨ìœ„ë¥¼ ì„ íƒí• ì§€ëŠ” ë¬¸ì œì˜ íŠ¹ì„±ê³¼ ë¶„ì„ ëª©ì ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì„ <b>í† í°í™”(Tokenization)</b>ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "### ë‹¨ì–´ìˆ˜ì¤€ í† í°í™”(Word-level Tokenization)\n",
    "\n",
    "ëŒ€ë¶€ë¶„ì˜ ì–¸ì–´ëŠ” ë„ì–´ì“°ê¸°ë¥¼ ì´ìš©í•´ ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. \n",
    "\n",
    "ë‹¨ì–´ìˆ˜ì¤€ í† í°í™”(Word-level Tokenization)ëŠ” ì´ì²˜ëŸ¼ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ë¯¸ ìˆëŠ” ê¸°ë³¸ ë‹¨ìœ„ì¸ ë‹¨ì–´ë¡œ ë¶„ë¦¬í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ë“¤ì–´, `\"good morning!\"`ì€ `[\"good\", \"morning\", \"!\"]`ê³¼ ê°™ì´ í† í°ë“¤ì˜ `list`ë¡œ ìª¼ê°œì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œ `\"!\"`ëŠ” ë‹¨ì–´ê°€ ì•„ë‹ˆë¼ êµ¬ë‘ì (punctuation)ì´ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ êµ¬ë‘ì ì€ ë³„ê°œì˜ í† í°ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ë”°ë¼ì„œ í† í°(token) ì´ë¼ëŠ” ê°œë…ì€ ë‹¨ì–´ë¿ ì•„ë‹ˆë¼ êµ¬ë‘ì , ìˆ«ì, íŠ¹ìˆ˜ ê¸°í˜¸ê¹Œì§€ í¬ê´„í•˜ëŠ” ê°œë…ì…ë‹ˆë‹¤.\n",
    "\n",
    "í† í°í™”ê°€ ì™„ë£Œë˜ê³  ë‚˜ë©´ ë¬¸ì¥ì€ <b>í† í°ë“¤ì˜ ì‹œí€€ìŠ¤(sequence of tokens)</b>ë¡œ í‘œí˜„ë©ë‹ˆë‹¤\n",
    "\n",
    "### ê°„ë‹¨í•œ custom tokenzier\n",
    "\n",
    "ì•„ë˜ì— ì •ì˜ëœ `simple_tokenizer`í•¨ìˆ˜ëŠ” ì´í•´ë¥¼ ì‰½ê²Œí•˜ê¸° ìœ„í•´ ë§¤ìš° ë‹¨ìˆœí™”ëœ í† í°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    " - ëª¨ë“  ëŒ€ë¬¸ìëŠ” `.lower()`ë©”ì„œë“œë¥¼ ì´ìš©í•˜ì—¬ ì†Œë¬¸ìë¡œ ë³€ê²½í•©ë‹ˆë‹¤ .\n",
    " - `[\".\", \"!\", \";\", \"'\", ...]` ë“±ì˜ êµ¬ë‘ì (punctuation)ì€ ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.\n",
    " - ë„ì–´ì“°ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ë‹¨ìœ„ í† í°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    \"\"\" lowercase the text, remove punctuation, and split into words \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for label, text in train_iter:\n",
    "    tokens = simple_tokenizer(text)\n",
    "    print(f\"Original Text:\\n{text}\")\n",
    "    print(f\"\\nTokenzied Text:\\n{tokens}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Vocabulary\n",
    "ëª¨ë“  Corpusì— ëŒ€í•˜ì—¬ í† í°í™”ë¥¼ ìˆ˜í–‰í•˜ê³ , í…ìŠ¤íŠ¸ì— ë“±ì¥í•˜ëŠ” <b>ê³ ìœ í•œ(unique) í† í°ë“¤ì˜ ì§‘í•©</b>ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ì´ ì§‘í•©ì„ Vocabulary(vocab, $V$) ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Building vocabulary...\")\n",
    "\n",
    "token_counter = Counter()\n",
    "for label, text in train_iter:\n",
    "    tokens = simple_tokenizer(text)\n",
    "    token_counter.update(tokens)\n",
    "\n",
    "print(f\"Total unique tokens: {len(token_counter)}\")\n",
    "print(f\"Most common tokens: {token_counter.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€ë¶€ë¶„ì˜ ë‹¨ì–´ëŠ” ë§¤ìš° ì ê²Œ ë“±ì¥í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ 121,364ê°œì˜ í† í°ë“¤ ì¤‘ ì•½ 100,000ê°œëŠ” 10ë²ˆ ì´í•˜ë§Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Number of tokens with frequency == 1: \", len([w for w in token_counter.values() if w <= 1]))\n",
    "print(f\"Number of tokens with frequency < 10: \", len([w for w in token_counter.values() if w < 10]))\n",
    "\n",
    "plot_token_frequency_histogram(token_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `<unk>` special token\n",
    "\n",
    "ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë“¤ì€ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ì¶©ë¶„í•œ ì˜ë¯¸ì  ë§¥ë½ì„ ì œê³µí•˜ì§€ ëª»í•˜ë©°, ëª¨ë¸ ê³¼ì í•©(overfitting)ì˜ ì›ì¸ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ ì¼ë°˜ì ìœ¼ë¡œ <b>ê°€ì¥ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ìƒìœ„ $N$ê°œì˜ ë‹¨ì–´ë§Œì„ ìœ íš¨í•œ vocabulary</b>ë¡œ ì„ íƒí•˜ë©°, ê·¸ ì™¸ì˜ ëª¨ë“  ë‹¨ì–´ëŠ” íŠ¹ë³„ í† í° `<unk>` (unknown token) ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì ‘ê·¼ë²•ì€ ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ì´ í›ˆë ¨ ì¤‘ `<unk>` í† í°ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì—, ì²˜ìŒ ë³´ëŠ” ë‹¨ì–´ê°€ ë‚˜ì˜¤ë”ë¼ë„ ì£¼ë³€ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ë¥¼ ì¶”ë¡ í•˜ë„ë¡ í•™ìŠµë¨\n",
    "- í›ˆë ¨ ë°ì´í„°ì—ëŠ” ì—†ì§€ë§Œ ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ìƒˆë¡­ê²Œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ ìˆë”ë¼ë„, ëª¨ë¸ì´ ì–´ëŠì •ë„ <b>ì¼ë°˜í™”ëœ ì„±ëŠ¥</b>ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œëŠ” ìƒìœ„ 20,000ê°œ í† í°ì„ vocabularyë¡œ ì‚¬ìš©í•˜ê³ , ê·¸ ì™¸ì˜ ë‚˜ë¨¸ì§€ ë‹¨ì–´ë“¤ì„ í‘œí˜„í•˜ê¸° ìœ„í•œ `<unk>`í† í°ì„ ì •ì˜í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "most_common_tokens = token_counter.most_common(20000)\n",
    "\n",
    "vocab = ['<unk>'] + [token for token, _ in most_common_tokens] # reserve index 0 for <unk>\n",
    "token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "UNK_IDX = token2idx['<unk>']\n",
    "\n",
    "print(f\"vocab_size = {vocab_size} (+1 for <unk>)\")\n",
    "print(\"vocab[:10]: \", vocab[:10])\n",
    "print(\"token2idx dict: \", dict(list(token2idx.items())[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding for text vectorization\n",
    "\n",
    "í† í°í™”ê°€ ì™„ë£Œëœ í›„ì—ëŠ”, í…ìŠ¤íŠ¸ë¥¼ ì»´í“¨í„°ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ«ì í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ <b>í…ìŠ¤íŠ¸ ë²¡í„°í™”(Text Vectorization)</b> ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê°€ì¥ ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ë²¡í„°í™” ë°©ë²•ìœ¼ë¡œëŠ” ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "$$\\mathbf{e}_i \\in\\{0,1\\}^{|V|}$$\n",
    "\n",
    "- One-hot Encodingëœ ë²¡í„°ì˜ ê¸¸ì´ëŠ” vocabularyì˜ í¬ê¸° $|V|$ì™€ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "- ëŒ€ë¶€ë¶„ì˜ ì›ì†Œê°€ `0`ì´ë¯€ë¡œ í¬ì†Œ ë²¡í„°(sparse vector)ì…ë‹ˆë‹¤.\n",
    "- ë˜í•œ, ë‹¨ì–´ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±(ì˜ˆ: like, love, adore)ì„ ì „í˜€ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì•„ë˜ ì½”ë“œëŠ” IMDB ë°ì´í„°ì…‹ì„ í† í°í™”í•œ í›„, One-hot Encodingì„ ì ìš©í•˜ì—¬ `Tensor`ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "- í¬ê·€ ë‹¨ì–´ (ì˜ˆ: curiousyellow)ëŠ” ëª¨ë‘ `<unk>` í† í°(`UNK_IDX = 0`)ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.\n",
    "- ìµœì¢…ì ìœ¼ë¡œ `Tensor`ëŠ” `[# of tokens, vocab_size]`ì˜ shapeì„ ê°€ì§‘ë‹ˆë‹¤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_tokens(token_indices, vocab_size):\n",
    "    \"\"\"\n",
    "    Given a list of token indices, return a tensor of shape\n",
    "    [len(token_indices), vocab_size] where each row is a one-hot vector.\n",
    "    \"\"\"\n",
    "    onehot_tensor = torch.zeros(len(token_indices), vocab_size)\n",
    "    for i, idx in enumerate(token_indices):\n",
    "        onehot_tensor[i, idx] = 1.0\n",
    "    return onehot_tensor\n",
    "\n",
    "for label, text in train_iter:\n",
    "    tokens = simple_tokenizer(text)\n",
    "    token_idxs = [token2idx.get(t, UNK_IDX) for t in tokens]\n",
    "    onehot_tensor = one_hot_encode_tokens(token_idxs, vocab_size)\n",
    "    \n",
    "    print(f\"Text:\\t {text}\\n\")\n",
    "    print(f\"Tokens:\\t {tokens}\\n\")\n",
    "    print(\"Indices:\", token_idxs)\n",
    "    print(\"\\nOne-hot encoded Tensor shape:\", onehot_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchText tokenizer\n",
    "PyTorchì˜ `TorchText`ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ë¥¼ ê°„ë‹¨íˆ í•˜ê¸° ìœ„í•œ tokenizerì™€ vocabularyë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•´ì£¼ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤\n",
    "\n",
    "ì•„ë˜ ì½”ë“œëŠ” TorchTextì˜ ê¸°ë³¸ tokenizerì¸ `basic_english`ë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\") \n",
    "\n",
    "for label, text in train_iter:\n",
    "    tokens = tokenizer(text)\n",
    "    print(f\"Original Text:\\n{text}\")\n",
    "    print(f\"\\nTokenzied Text:\\n{tokens}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabularies\n",
    "\n",
    "TorchTextì—ì„œëŠ” `build_vocab_from_iterator` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ `Vocab` (vocabulary) ê°ì²´ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    " - ì´ í•¨ìˆ˜ëŠ” í† í° ë¦¬ìŠ¤íŠ¸(iterator)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê° í† í°ì˜ ë¹ˆë„ë¥¼ ê³„ì‚°í•œ ë’¤, unique tokenë“¤ì„ ì •ìˆ˜ ì¸ë±ìŠ¤ì™€ ë§¤í•‘í•œ `Vocab` ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    " - `Vocab` ê°ì²´ëŠ” í† í°ì„ ì…ë ¥ë°›ì•„ í•´ë‹¹ í† í°ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” <b>ì‚¬ì „(dictionary)</b> ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "   - ì˜ˆ: `vocab[\"hello] â†’ 1`,  `vocab[\"world\"] â†’ 2`, ...\n",
    " - `min_freq`: ì§€ì •ëœ ìµœì†Œ ë“±ì¥ ë¹ˆë„ë³´ë‹¤ ì ê²Œ ë‚˜íƒ€ë‚œ ë‹¨ì–´ëŠ” `<unk>`ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
    " - `specials`: ì‚¬ì „ì— í¬í•¨ì‹œí‚¬ spatial tokenë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "   - ì˜ˆ: `<unk>` = unknown, `<pad>` = padding\n",
    "   - ì´ëŸ¬í•œ íŠ¹ìˆ˜ í† í°ë“¤ì€ vocabularyì˜ ê°€ì¥ ì• ì¸ë±ìŠ¤ì— ë°°ì¹˜ë©ë‹ˆë‹¤.\n",
    " - `set_default_index(vocab[\"<unk>\"])` vocabularyì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í† í°(OOV, out-of-vocabulary)ì´ ì…ë ¥ë  ê²½ìš° ë°˜í™˜í•  ê¸°ë³¸ ì¸ë±ìŠ¤ë¥¼ `<unk>`í† í°ì˜ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "<mark>ì£¼ì˜</mark>\n",
    "`Vocab`ì€ ë°˜ë“œì‹œ <b>í•™ìŠµ(training) ë°ì´í„°</b>ë§Œì„ ì´ìš©í•˜ì—¬ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    " - ê²€ì¦(validation) ë˜ëŠ” í…ŒìŠ¤íŠ¸(test) ë°ì´í„°ë¡œ vocabularyë¥¼ ë§Œë“¤ë©´, ëª¨ë¸ì´ í•™ìŠµ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ì–´ ì •ë³´ë¥¼ ë¯¸ë¦¬ ì•Œê²Œ ë˜ì–´ <b>ì •ë³´ ëˆ„ì¶œ(information leakage)</b> ì´ ë°œìƒí•©ë‹ˆë‹¤.\n",
    " - ì´ëŠ” validation/test ë‹¨ê³„ì—ì„œì˜ ì„±ëŠ¥ í‰ê°€ë¥¼ ë‚™ê´€ì (over-optimistic)ìœ¼ë¡œ ë³´ì´ë„ë¡ ë§Œë“¤ì–´ ë¶€ì •í™•í•œ ì„±ëŠ¥ í‰ê°€ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\") \n",
    "\n",
    "token_lists = []\n",
    "for label, text in train_iter:\n",
    "    tokens = tokenizer(text)\n",
    "    token_lists.append(tokens)\n",
    "\n",
    "vocab = build_vocab_from_iterator(token_lists, specials=[\"<unk>\", \"<pad>\"], min_freq = 2)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Vocab`ê°ì²´ëŠ” ì‚¬ì „ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤. ì¦‰, tokenì„ ì „ë‹¬í•˜ë©´ ê·¸ tokenì— í•´ë‹¹í•˜ëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤(index)ê°€ ë°˜í™˜ë©ë‹ˆë‹¤.\n",
    "- ê° í† í°ì˜ ì¸ë±ìŠ¤ëŠ” ë“±ì¥ ë¹ˆë„(frequency) ì— ë”°ë¼ í• ë‹¹ë©ë‹ˆë‹¤.\n",
    "- ì¦‰, ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” í† í°ì¼ìˆ˜ë¡ ì‘ì€ ì¸ë±ìŠ¤ë¥¼ ê°–ê³ , ë“œë¬¼ê²Œ ë“±ì¥í•˜ëŠ” í† í°ì¼ìˆ˜ë¡ í° ì¸ë±ìŠ¤ë¥¼ ê°–ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Index of token 'the` : \", vocab[\"the\"])\n",
    "print(\"Index of token 'hate`: \", vocab[\"hate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_itos()` ë©”ì„œë“œ\n",
    "- itosëŠ” int-to-string ì˜ ì•½ìë¡œ, `get_itos()`ë©”ì„œë“œëŠ” ì¸ë±ìŠ¤ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len` ë©”ì„œë“œë¥¼ í†µí•´ `vocab_size`(number of unique tokens)ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"vocab_size = {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabularyì— ì—†ëŠ” OOV í† í°ì„ ì „ë‹¬í•˜ë©´ `<unk>` í† í°ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ê°€ ë¦¬í„´ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” ì•ì„œ `set_default_index` ë©”ì„œë“œë¥¼ í†µí•´ ê¸°ë³¸ê°’ì„ `vocab[\"<unk>\"]`ìœ¼ë¡œ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "vocab[\"Jinhyun\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ ì˜ˆì‹œëŠ” ì„ì˜ì˜ ë¬¸ì¥ì„ í† í°í™”í•œ í›„, vocabularyë¥¼ ì‚¬ìš©í•´ ê° í† í°ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "sentence = \"Hi, my name is Jinhyun! I'm enjoying this course.\"\n",
    "\n",
    "print(\"Tokens\\t\\t:\", tokenizer(sentence))\n",
    "print(\"Token indices\\t:\", vocab(tokenizer(sentence)))\n",
    "print(\"Index of <unk>:\", vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ê³¼ì •ë“¤ì„ í•¨ìˆ˜í™”í•˜ì—¬ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì •ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "- `text_pipeline`: ì…ë ¥ ë¬¸ì¥ì„ `tokenizer`ë¡œ í† í°í™”í•œ ë’¤, ê° í† í°ì„ `vocab`ì„ ì´ìš©í•˜ì—¬ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- `label_pipeline`: `1`, `2`ì˜ ê°’ì„ ê°€ì§€ëŠ” IMDB ë°ì´í„°ì…‹ì˜ ë¼ë²¨ì„ `0`, `1`ì˜ ê°’ì„ ê°€ì§€ë„ë¡ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "  - `0`: Negative review\n",
    "  - `1`: Positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "print(text_pipeline(\"Hello, world!\"))\n",
    "print(label_pipeline(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate batch\n",
    "ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ <b>mini-batch</b>ë‹¨ìœ„ë¡œ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë‚˜ í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë¬¸ì¥ë§ˆë‹¤ í¬í•¨ëœ í† í°(token) ìˆ˜ê°€ ì œê°ê°ì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ ê·¸ëŒ€ë¡œ í•˜ë‚˜ì˜ í…ì„œ(batch)ë¡œ ë¬¶ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ íˆìŠ¤í† ê·¸ë¨ì„ í†µí•´ exampleë³„ë¡œ ê° í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” í† í° ìˆ˜ê°€ ë§¤ìš° ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "token_counts_per_text = [len(text_pipeline(text)) for label, text in train_iter]\n",
    "\n",
    "plot_token_count_histogram(token_counts_per_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handles Sequences of Varying Length\n",
    "RNNì€ ì´ë¡ ì ìœ¼ë¡œ ì„ì˜ì˜ ê¸¸ì´(sequence length)ë¥¼ ê°€ì§„ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ê·¸ëŸ¬ë‚˜ ì‹¤ì œ í•™ìŠµì—ì„œëŠ” `DataLoader`ë¥¼ ì´ìš©í•˜ì—¬ ì…ë ¥ ë°ì´í„°ë“¤ì„ <b>ë¯¸ë‹ˆë°°ì¹˜(mini-batch)</b> ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë•Œ, ê°™ì€ mini-batch ì•ˆì˜ ëª¨ë“  ì…ë ¥ ì‹œí€€ìŠ¤ë“¤ì€ ë°˜ë“œì‹œ ë™ì¼í•œ ê¸¸ì´ì—¬ì•¼ `Tensor`ë¡œ ë³€í™˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### Padding\n",
    "\n",
    "ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ë“¤ì„ ë‹¤ë£¨ê¸° ìœ„í•´ì„œ <b>padding</b>ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê¸´ ê²½ìš° (Token length > `MAX_LEGNTH`) -> ë’·ë¶€ë¶„ì„ ì˜ë¼ëƒ…ë‹ˆë‹¤(trucncate).\n",
    "- ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ì§§ì€ ê²½ìš° (Token length < `MAX_LEGNTH`) -> `<pad>`í† í°ì„ ì±„ì›Œ ê¸¸ì´ë¥¼ `MAX_LEGNTH`ë¡œ ë§ì¶°ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, `MAX_LEGNTH = 4`ì¸ ê²½ìš°,\n",
    " - `[\"i\", \"really\", \"hate\", \"music\", \"videos\"]` $\\rightarrow$ `[\"i\", \"really\", \"hate\", \"music\"]`\n",
    " - `[\"i\", \"love\", \"pizza\"]` $\\rightarrow$ `[\"i\", \"really\", \"hate\", \"<pad>\"]`\n",
    "\n",
    "\n",
    "`MAX_LEGNTH` ê°’ì„ ì„¤ì •í•˜ëŠ” í•œê°€ì§€ ë°©ë²•ì€ í•™ìŠµ ë°ì´í„°ì—ì„œ ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” í•™ìŠµ ë°ì´í„°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” í† í° ê°œìˆ˜ ë¶„í¬ì˜ ìµœë¹ˆê°’ì„ ì‚¬ìš©í•˜ì—¬ `MAX_LEGNTH`ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤\n",
    "\n",
    "---\n",
    "\n",
    "<mark>ì‹¤ìŠµ</mark> `collate_batch`í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "`DataLoader`ëŠ” ì…ë ¥ ë°ì´í„°ë“¤ì„ mini-batchë¡œ ë¬¶ì–´ì¤„ ë•Œ `collate_fn` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, ì´ë¥¼ ìœ„í•œ í•¨ìˆ˜ë¥¼ ì§ì ‘ ì •ì˜í•¨ìœ¼ë¡œì¨ ì…ë ¥ë°ì´í„°ë“¤ì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    " - [`torch.cat`](https://docs.pytorch.org/docs/stable/generated/torch.cat.html) í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì„¸ìš”.\n",
    " - `nn.utils.rnn.pad_sequence`í•¨ìˆ˜ëŠ” ì‚¬ìš©í•˜ì§€ <u>ë§ˆì„¸ìš”</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    Convert a batch of (label, text) pairs into fixed-length tensors.\n",
    "    \n",
    "    Each text is tokenized, then either truncated or padded with the \"<pad>\" token\n",
    "    so that all texts in the batch have the same length (MAX_LENGTH).\n",
    "    \n",
    "    Args:\n",
    "        batch: A list of tuples (label, text).\n",
    "    \n",
    "    Returns:\n",
    "        text_tensor: Tensor of shape (batch_size, MAX_LENGTH) with token indices.\n",
    "        label_tensor: Tensor of shape (batch_size,) with the corresponding labels.\n",
    "        lengths_tensor: Tensor of shape (batch_size,) with each sequenceâ€™s true length.\n",
    "\n",
    "    \"\"\"\n",
    "    label_list, text_list, length_list  = [], [], []\n",
    "    pad_token_index = vocab[\"<pad>\"]\n",
    "\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.long)\n",
    "\n",
    "        length_list.append(min(processed_text.shape[0], MAX_LENGTH))\n",
    "\n",
    "        if processed_text.shape[0] > MAX_LENGTH:\n",
    "            processed_text = ... # TODO\n",
    "        else:\n",
    "            padding = torch.full((MAX_LENGTH - processed_text.shape[0],), pad_token_index, dtype=torch.long)\n",
    "            processed_text = ... # TODO\n",
    "\n",
    "        text_list.append(processed_text)\n",
    "\n",
    "    text_tensor = torch.stack(text_list)  # shape: (batch_size, MAX_LENGTH)\n",
    "    label_tensor = torch.tensor(label_list, dtype=torch.long)\n",
    "    lengths_tensor = torch.tensor(length_list, dtype=torch.long)\n",
    "    return text_tensor, label_tensor, lengths_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "batch = [\n",
    "    (1, \"It was totally a waste of time.\"),\n",
    "    (2, \"The movie was amazing!\"),\n",
    "]\n",
    "\n",
    "text_tensor, label_tensor, length_tensor = collate_batch(batch)\n",
    "\n",
    "print(\"text_tensor.shape:\", text_tensor.shape)\n",
    "print(\"Text tensor:\\n\", text_tensor)\n",
    "print(\"\\nLabel tensor:\", label_tensor)\n",
    "print(\"Length tensor:\", length_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "``` python\n",
    "text_tensor.shape: torch.Size([2, 256])\n",
    "Text tensor:\n",
    " tensor([[ 11,  17, 483,   6, 444,   7,  68,   3,   1,   1,   1,   1,   1,   1,\n",
    "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    " ...          \n",
    "           1,   1,   1,   1],\n",
    "        [  2,  21,  17, 476,  36,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
    "...\n",
    "           1,   1,   1,   1]])\n",
    "\n",
    "Label tensor: tensor([0, 1])\n",
    "Length tensor: tensor([8, 5])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `collate_batch` with `DataLoader`\n",
    "\n",
    "ì •ì˜í•œ `collate_batch`í•¨ìˆ˜ë¥¼ `DataLoader`ì— ì „ë‹¬í•˜ì—¬ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê³ ì •ëœ mini-batchë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(train_iter, batch_size = batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_iter, batch_size = batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "for X, y, length in test_dataloader:\n",
    "    print(\"Batch X shape:\", X.shape)\n",
    "    print(\"Batch y shape:\", y.shape)\n",
    "\n",
    "    print(\"First batch 3rd example:\", X[2])\n",
    "    print(\"First batch label:\", y)\n",
    "    print(\"First batch length:\", length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "ê° í† í°ì„ $d$-ì°¨ì›ì˜ ì‹¤ìˆ˜ ë²¡í„°(dense vector)ë¡œ ë§¤í•‘í•˜ì—¬ í‘œí˜„í•˜ëŠ” ê²ƒì„ <b>word embedding</b>ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "For each token $t_i \\in V$ ($V$: vocabulary),\n",
    "$$ t_i \\mapsto \\mathbf{e}_i \\in \\mathbb{R}^d , \\quad(d \\ll |V|)$$\n",
    "\n",
    " - one-hotë²¡í„°ëŠ” ëŒ€ë¶€ë¶„ì˜ ê°’ì´ `0`ì´ë©° í¬ì†Œ ë²¡í„°(sparse vector)ì¸ë° ë°˜í•´, ì„ë² ë”© ë²¡í„°ëŠ” $d$ì°¨ì›ì˜ dense vectorë¡œ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë” íš¨ìœ¨ì ì´ê³  ì»´íŒ©íŠ¸í•˜ê²Œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Embedding Matrix\n",
    "\n",
    "Vocabulary $V$ë‚´ì˜ ëª¨ë“  tokenë“¤ì— ëŒ€í•œ ì„ë² ë”©ì€ í•˜ë‚˜ì˜ ì„ë² ë”© í–‰ë ¬(Embedding Matrix) $E$ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$ E \\in \\mathbb{R}^{|V| \\times d} $$\n",
    "\n",
    "- í† í° ì¸ë±ìŠ¤ $t_i$ì— ëŒ€ì‘í•˜ëŠ” í–‰(row)ì„ ì„ íƒí•˜ë©´, í•´ë‹¹ í† í°ì˜ ì„ë² ë”© ë²¡í„° $\\mathbf{e}_i \\in \\mathbb{R}^d$ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### `nn.Embedding` ë ˆì´ì–´ (embedding layer)\n",
    "\n",
    "PyTorchì—ì„œëŠ” `nn.Embedding`í´ë˜ìŠ¤ë¥¼ í†µí•´ ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ ë ˆì´ì–´ëŠ” í† í°ì˜ ì¸ë±ìŠ¤ë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ í† í°ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜í•˜ëŠ” <b>ë£©ì—… í…Œì´ë¸”(lookup table)</b>ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "``` python\n",
    "nn.Embedding(num_embeddings, embedding_dim, padding_idx=None)\n",
    "```\n",
    "\n",
    "- `num_embeddings`: vocabulary í¬ê¸° $|V|$ (vocab_size)\n",
    "- `embedding_dim`: embedding ë²¡í„°ì˜ ì°¨ì› $d$\n",
    "- `padding_idx`: `<pad>` í† í° ì¸ë±ìŠ¤ë¥¼ ì§€ì •í•˜ë©´, í•´ë‹¹ í† í°ì˜ ì„ë² ë”© ë²¡í„°ëŠ” í•­ìƒ `0`ìœ¼ë¡œ ê³ ì •ë˜ì–´ í•™ìŠµë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "- `nn.Embedding`ë ˆì´ì–´ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ $|V| \\times d$ í¬ê¸°ì˜ Embedding Matrixë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "  - tokenì˜ ì¸ë±ìŠ¤ë¥¼ ì „ë‹¬ë°›ìœ¼ë©´ shapeì´ `[embed_dim]`ì¸ ì„ë² ë”© `Tensor`ë¥¼ ë¦¬í„´í•´ì¤ë‹ˆë‹¤.\n",
    "  - ë§Œì•½ ì…ë ¥ì˜ shapeì´ `[batch_size, seq_len]`ì´ë©´, ì¶œë ¥ì˜ shapeì€ `[batch_size, seq_len, embed_dim]`ì…ë‹ˆë‹¤\n",
    "\n",
    "### word embddingì„ ì–»ëŠ” ë°©ë²•\n",
    "1. ëœë¤ ì´ˆê¸°í™” í›„ í•™ìŠµ (train from scractch)\n",
    "   - Embedding Matrixë¥¼ ëœë¤ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê³ , ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì—ì„œ <b>ì—­ì „íŒŒ(backpropagation)</b>ë¥¼ í†µí•´ ì„ë² ë”© ë²¡í„°ê°€ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n",
    "2. ì‚¬ì „í•™ìŠµ ì„ë² ë”© í™œìš© (pretrained word-embeddings)\n",
    "   - Word2Vec, GloVe ë“± ì‚¬ì „ í•™ìŠµëœ ì„ë² ë”©ì„ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings = 10, \n",
    "                               embedding_dim = 3, \n",
    "                               padding_idx = 0)\n",
    " \n",
    "input_token_ids = torch.LongTensor([[1,2,4,5],[4,3,2,0]]) # (batch_size, seq_length) = (2, 4)\n",
    "output_embedded = embedding_layer(input_token_ids)\n",
    "\n",
    "print(\"nn.Embedding output shape:\", output_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification model\n",
    "\n",
    "<mark>ì‹¤ìŠµ</mark> LSTMì„ ì´ìš©í•˜ì—¬ IMBD ì˜í™” ë¦¬ë·° ê°ì • ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ `SentimentClassifier`ë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    "1. `nn.Embedding`ë¥¼ ì´ìš©í•˜ì—¬ í† í° ì¸ë±ìŠ¤ë¥¼ $d$-ì°¨ì› ì„ë² ë”© ë²¡í„°ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤\n",
    "2. íŒ¨ë”©ëœ ì‹œí€€ìŠ¤ ì²˜ë¦¬ (`pack_padded_sequence`)\n",
    "   - `nn.utils.rnn.pack_padded_sequence` ([docs](https://docs.pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html))í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ë©´ `<pad>`í† í°ì„ ë¬´ì‹œí•˜ê³  RNN/LSTMì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "   - ì´ í•¨ìˆ˜ëŠ” paddingëœ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•í•˜ì—¬ `PackedSequence` ê°ì²´ë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤\n",
    "   - Arguments:\n",
    "     - ì‹œí€€ìŠ¤ ê¸¸ì´ ì •ë³´ëŠ” CPU ë©”ëª¨ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤. `torch.Tensor.cpu`ë¥¼ ì´ìš©í•˜ì„¸ìš”.\n",
    "     - `batch_first = True`ë¡œ ì„¤ì •í•˜ì—¬ ì…ë ¥ í…ì„œì˜ shapeì´ `(batch_size, seq_length, ...)` ì„ì„ ì§€ì •í•©ë‹ˆë‹¤\n",
    "       - `batch_first = False`ì¸ ê²½ìš° ì…ë ¥ í…ì„œì˜ shapeì€ `(seq_length, batch_size, ...)`ì…ë‹ˆë‹¤.\n",
    "     - `enforce_sorted = False`ë¡œ ì„¤ì •í•˜ì—¬, ì…ë ¥ ì‹œí€€ìŠ¤ë“¤ì´ ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆì§€ ì•ŠìŒì„ ì§€ì •í•©ë‹ˆë‹¤\n",
    "\n",
    "3. `nn.LSTM`ì— `PackedSequence`ë¥¼ ì „ë‹¬í•˜ì—¬ ê° ì‹œì  $t$ì—ì„œì˜ hidden state $\\mathbf{h}_t$ì™€ cell state $\\mathbf{c}_t$ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "   - `nn.LSTM` ëª¨ë“ˆì˜ ì¶œë ¥ê°’ì€ [docs](https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
    "4. ë§ˆì§€ë§‰ LSTM layerì˜ final hidden state $\\mathbf{h}_T$ë¥¼ ì´ìš©í•˜ì—¬ classification logits ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    $$\\mathbf{\\hat{y}} = \\mathbf{W}_{hy}\\mathbf{h}_T + \\mathbf{b}_y$$\n",
    "   - `self.fc`(`nn.Linear`)ë¥¼ í™œìš©í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    \"\"\" Sentiment classification model using an LSTM. \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, num_classes, pad_index):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_index)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_length) with token indices.\n",
    "            lengths: Tensor of shape (batch_size,) with the true lengths of each sequence.\n",
    "\n",
    "        Returns:\n",
    "            logits: Tensor of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SentimentClassifier(\n",
    "    vocab_size = len(vocab),\n",
    "    embed_dim = 128,\n",
    "    hidden_dim = 128,\n",
    "    num_layers = 3,\n",
    "    num_classes = 2,\n",
    "    pad_index= vocab['<pad>']\n",
    ").to(device)\n",
    "\n",
    "X = torch.randint(0, 10, (8, 50)).to(device)  # (batch_size, seq_len)\n",
    "lengths = torch.randint(1, 50, (8,)).to(device)  # lengths tensor with shape (batch_size, ) for each sequence in the batch\n",
    "logits = model(X, lengths)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)  # (batch_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "\n",
    "RNN/LSTM ê³„ì—´ ëª¨ë¸ì€ í›ˆë ¨ ê³¼ì •ì—ì„œ <b>gradient exploding</b> ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ê¸°ìš¸ê¸°(gradient) ê°’ì´ ì§€ë‚˜ì¹˜ê²Œ ì»¤ì ¸ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§€ëŠ” í˜„ìƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ `torch.nn.utils.clip_grad_norm_` ([docs](https://docs.pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)) í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ gradient clippingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, dataloader, criterion, optimizer, epoch):\n",
    "    \"\"\" train for one epoch \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    for X, y, lengths in dataloader:\n",
    "        X, y, lengths = X.to(device), y.to(device), lengths.to(device)\n",
    "\n",
    "        logits = model(X, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += (logits.argmax(dim = 1) == y).type(torch.float).sum().item()\n",
    "        total_samples += batch_size\n",
    "        \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sentiment_classifier():\n",
    "    num_epochs = 5\n",
    "    learning_rate = 1e-3       # Learning rate\n",
    "    batch_size = 64\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    embed_dim = 128\n",
    "    hidden_dim = 128\n",
    "    num_layers = 2\n",
    "    num_classes = 2\n",
    "    pad_index = vocab[\"<pad>\"]\n",
    "    \n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_iter, test_iter = torchtext.datasets.IMDB(root = \"/datasets/NLP\")\n",
    "    \n",
    "    train_dataloader = DataLoader(train_iter, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "    test_dataloader = DataLoader(test_iter, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "    \n",
    "    model = SentimentClassifier(vocab_size = vocab_size, embed_dim = embed_dim, hidden_dim = hidden_dim,\n",
    "                                num_layers = num_layers, num_classes = num_classes, pad_index = pad_index).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"Total number of model params : {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, device, train_dataloader, criterion, optimizer, epoch)\n",
    "        test_loss, test_accuracy = evaluate_one_epoch(model, device, test_dataloader, criterion, epoch)\n",
    "        print(f\"[Epoch {epoch + 1:02d}] Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model = train_sentiment_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì½”ë“œ êµ¬í˜„ì´ ì˜ ë˜ì—ˆë‹¤ë©´ ë³„ë„ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹(hyperparameter tuning)ì—†ì´ `Test accuracy > 80%`ë¥¼ ë‹¬ì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "## Prediction on new input text\n",
    "ì´ì œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì˜í™” ë¦¬ë·°ì— ëŒ€í•œ ê°ì •ì„ ì˜ˆì¸¡í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ê²°ê³¼ì—ì„œì™€ ê°™ì´ í•™ìŠµëœ LSTMëª¨ë¸ì€ ë‹¨ìˆœíˆ ë‹¨ì–´ì˜ ì¡´ì¬ ì—¬ë¶€ë§Œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼\n",
    " - \"not good\"ê³¼ ê°™ì´ ë‹¨ì–´ì˜ ìˆœì„œì™€ ì¡°í•©ì„ ê³ ë ¤í•˜ë©°,\n",
    " - \"I thought the movie would be terrible, but it was actually amazing.\" ë¦¬ë·°ì—ì„œì™€ ê°™ì´ ë¬¸ë§¥ì„ ì–´ëŠì •ë„ ì´í•´í•˜ë©° ì˜ë¯¸ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "imdb_labels = {1: \"ğŸ‘\", 2: \"ğŸ‘\"}\n",
    "\n",
    "def predict(model, text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(text_pipeline(text)).unsqueeze(0)\n",
    "        length = torch.tensor([X.shape[1]])\n",
    "        logits = model(X, length)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        predicted_label = logits.argmax(1).item() + 1\n",
    "        return predicted_label, probs\n",
    "\n",
    "sample_texts = [\n",
    "    (\"positive\", \"This movie was absolutely wonderful and touching.\"),\n",
    "    (\"negative\", \"The plot was boring and the acting was terrible.\"),\n",
    "    (\"positive\", \"I thought the movie would be terrible, but it was actually amazing.\"),\n",
    "    (\"negative\", \"The acting was good, but the plot ruined everything.\"),\n",
    "    (\"negative\", \"This movie is not good and not enjoyable\"),\n",
    "]\n",
    "\n",
    "for sentiment, text in sample_texts:\n",
    "    label, prob = predict(model.to(\"cpu\"), text, text_pipeline)\n",
    "    print(f\"Input Text ({sentiment}): '{text}'\")\n",
    "    print(f\"Predicted Label: {imdb_labels[label]}, Probabilities: {prob}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Word Embedding\n",
    "\n",
    "ìì—°ì–´ì²˜ë¦¬(NLP)ì—ì„œ í•™ìŠµ ë°ì´í„°ì…‹ì´ ì‘ì„ ë•Œ, ì‚¬ì „í•™ìŠµëœ word embeddingì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ì˜ˆë¥¼ë“¤ì–´, í•™ìŠµ ë°ì´í„°ì…‹ì— `\"I love you.\"`ë¼ëŠ” ë¬¸ì¥ë§Œ ë“±ì¥í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ `\"I adore you.\"`ë¼ëŠ” ë¬¸ì¥ì´ ë“±ì¥í–ˆë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "- `\"adore\"`ë¼ëŠ” ë‹¨ì–´ëŠ” í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ ì „í˜€ ë“±ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
    "- í•˜ì§€ë§Œ ì‚¬ì „í•™ìŠµëœ word embeddingì—ì„œëŠ” `love`ì˜ ì„ë² ë”© ë²¡í„°($\\mathbf{e}_{\\text{love}}$)ì™€ `adore`ì˜ ì„ë² ë”© ë²¡í„°($\\mathbf{e}_{\\text{adore}}$)ê°€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤.\n",
    "- ë”°ë¼ì„œ ëª¨ë¸ì€ `adore`ë¼ëŠ” ë³¸ ì  ì—†ëŠ” ìƒˆë¡œìš´ ë‹¨ì–´ë¼ë„ ê·¸ ì˜ë¯¸ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì‹¤ì œë¡œ GloVe ì„ë² ë”©ì—ì„œëŠ” `love`ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤(ì˜ˆ:heart, dear, beloved, adore)ì´ ì„ë² ë”© ê³µê°„ì—ì„œ ì„œë¡œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "- ì´ì²˜ëŸ¼ Word2Vec, GloVeì™€ ê°™ì€ ì‚¬ì „í•™ìŠµëœ ì„ë² ë”©ì€ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ì—†ê±°ë‚˜(OOV, out-of-vocabulary) ìì£¼ ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë“¤ì— ëŒ€í•´ì„œë„ ì¼ë°˜í™”í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "\n",
    "## GloVe ì„ë² ë”© \n",
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” ì‚¬ì „í•™ìŠµëœ GloVe (Global Vectors for Word Representation) ì„ë² ë”©ì„ í™œìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Loading pre-trained GloVe embeddings...\")\n",
    "glove = GloVe(name=\"6B\", dim=50, cache=\"/datasets/NLP/glove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GloVe` ê°ì²´ëŠ” íŒŒì´ì¬ ì‚¬ì „(dictionary)ì²˜ëŸ¼ ë™ì‘í•˜ë©°, ë‹¨ì–´(token)ì„ ì „ë‹¬í•˜ë©´ word embeddingì„ ë°˜í™˜ë°›ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"word embedding of 'cat': \\n\", glove[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "ì½”ì‚¬ì¸ ìœ ì‚¬ë„(cosine similarity)ëŠ” ë‘ ë²¡í„° ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•  ë•Œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‘ ë²¡í„° $u$ì™€ $v$ê°€ ì£¼ì–´ì¡Œì„ë•Œ, cosine similarityëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë©ë‹ˆë‹¤: \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 ||v||_2} = cos(\\theta)Â \\tag{1}$$\n",
    "\n",
    "* $u \\cdot v$: ë‘ ë²¡í„°ê°„ì˜ ë‚´ì (dot product)\n",
    "* $||u||_2$: ë²¡í„°ì˜ L2 norm\n",
    "* $\\theta$: ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„\n",
    "    * ë§Œì•½ $u$ì™€ $v$ê°€ ë¹„ìŠ·í•˜ë©´, cosine similarityê°’ì€ 1ì— ê°€ê¹Œì›Œì§‘ë‹ˆë‹¤.\n",
    "    * ë§Œì•½ ë‘ ë²¡í„°ì˜ ì°¨ì´ê°€ í¬ë©´, cosine similarityê°’ì€ 0ì— ê°€ê¹Œì›Œ ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(vec1, vec2):\n",
    "    return F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0)).item()\n",
    "\n",
    "word_a, word_b = \"love\", \"like\"\n",
    "similarity = compute_cosine_similarity(glove[word_a], glove[word_b])\n",
    "print(f\"Cosine similarity between '{word_a}' and '{word_b}': {similarity:.4f}\")\n",
    "\n",
    "word_a, word_b = \"love\", \"printer\"\n",
    "similarity = compute_cosine_similarity(glove[word_a], glove[word_b])\n",
    "print(f\"\\nCosine similarity between '{word_a}' and '{word_b}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-k word retrieval\n",
    "\n",
    "Word embedding ê³µê°„ì—ì„œëŠ” <b>ì˜ë¯¸ì ìœ¼ë¡œ ë¹„ìŠ·í•œ ë‹¨ì–´ë“¤ì´ ì„œë¡œ ê°€ê¹Œìš´ ìœ„ì¹˜</b>ì— ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "ë”°ë¼ì„œ íŠ¹ì • ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ì„ë² ë”© ê³µê°„ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ top-kê°œì˜ ë‹¨ì–´ë“¤ì„ ê²€ìƒ‰í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def retrieve_top_k_similar(query, glove, k = 5):\n",
    "    \"\"\" Returns the top-k most similar words to `query`, with scores. \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    assert query in glove.stoi, f\"â€˜{query}â€™ not in GloVe vocabulary\"\n",
    "\n",
    "    query_vec = glove[query].to(device)    # [D]\n",
    "    embedding_matrix = glove.vectors.to(device)  # [V, D]\n",
    "\n",
    "    # Cosine similarity = dot / (||u|| * ||v||)\n",
    "    cos_similarities = (embedding_matrix @ query_vec) / (embedding_matrix.norm(dim=1) * query_vec.norm() + 1e-8)  # [V]\n",
    "    topk = torch.topk(cos_similarities, k + 1)  # +1 because query itself has sim = 1\n",
    "\n",
    "    retrieved_words = []\n",
    "    for idx, score in zip(topk.indices.tolist(), topk.values.tolist()):\n",
    "        word = glove.itos[idx]\n",
    "        if word != query:\n",
    "            retrieved_words.append((word, score))\n",
    "    return retrieved_words\n",
    "\n",
    "query_word = \"king\"\n",
    "top5 = retrieve_top_k_similar(query_word, glove, k=5)\n",
    "print(f\"Top 5 words similar to {query_word}:\")\n",
    "for w, sim in top5:\n",
    "    print(f\"    {w:10s}  cosine_similarity = {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE visualization\n",
    "\n",
    "ê³ ì°¨ì› word embeddingì„ 2Dë¡œ íˆ¬ì˜í•´ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì´ ì–´ë–»ê²Œ ê°€ê¹ê²Œ ë°°ì¹˜ë˜ëŠ”ì§€ë¥¼ ì‹œê°í™” í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tsne(words, categories, glove):\n",
    "    vecs = torch.stack([glove[w] for w in words])\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state = 42, perplexity = 30)\n",
    "    proj = tsne.fit_transform(vecs.numpy())\n",
    "\n",
    "    unique_category = sorted(set(categories))\n",
    "    cmap = plt.get_cmap('tab10', len(unique_category))\n",
    "    category_to_color = {cat: cmap(i) for i, cat in enumerate(unique_category)}\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, word in enumerate(words):\n",
    "        cat = categories[i]\n",
    "        plt.scatter(proj[i, 0], proj[i, 1],\n",
    "                    color=category_to_color[cat])\n",
    "        plt.annotate(word, (proj[i, 0], proj[i, 1]), fontsize=9)\n",
    "\n",
    "    plt.title(\"t-SNE Projection of GloVe Embeddings\")\n",
    "    # plt.legend(loc=\"best\", frameon=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "words_example = [\n",
    "    \"cat\", \"dog\", \"lion\", \"tiger\", \"elephant\", \"whale\", \"shark\", \"eagle\", \"owl\", \"frog\",\n",
    "    \"apple\", \"banana\", \"orange\", \"grape\", \"mango\", \"pineapple\", \"lemon\", \"cherry\", \"peach\", \"pear\",\n",
    "    \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"orange\", \"pink\", \"brown\", \"black\", \"white\",\n",
    "    \"car\", \"truck\", \"bicycle\", \"motorcycle\", \"airplane\", \"train\", \"boat\", \"ship\", \"submarine\", \"helicopter\",\n",
    "    \"doctor\", \"engineer\", \"teacher\", \"artist\", \"lawyer\", \"chef\", \"nurse\", \"pilot\", \"scientist\", \"farmer\",\n",
    "    \"happy\", \"sad\", \"angry\", \"surprised\", \"scared\", \"confident\", \"excited\", \"bored\", \"jealous\", \"proud\",\n",
    "    \"computer\", \"smartphone\", \"internet\", \"software\", \"hardware\", \"robot\", \"drone\", \"server\", \"database\", \"algorithm\",\n",
    "    \"circle\", \"square\", \"triangle\", \"rectangle\", \"hexagon\", \"octagon\", \"star\", \"heart\", \"diamond\", \"oval\",\n",
    "    \"bread\", \"rice\", \"pasta\", \"pizza\", \"burger\", \"sushi\", \"salad\", \"soup\", \"steak\", \"taco\",\n",
    "    \"run\", \"jump\", \"swim\", \"read\", \"write\", \"sing\", \"dance\", \"cook\", \"drive\", \"sleep\",\n",
    "]\n",
    "\n",
    "words_categories = [\"Animal\"] * 10 + [\"Fruit\"] * 10 + [\"Color\"] * 10 + [\"Vehicle\"] * 10 + \\\n",
    "    [\"Profession\"] * 10 +  [\"Emotion\"] * 10 + [\"Technology\"] * 10 + [\"Shape\"] * 10 + [\"Food\"] * 10 + [\"Verb\"] * 10 \n",
    "\n",
    "plot_tsne(words_example, words_categories, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ t-SNE ì‹œê°í™” ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´ ì•„ë˜ì™€ ê°™ì€ í¥ë¯¸ë¡œëŠ” ê²°ê³¼ë“¤ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ë‹¨ì–´ ê·¸ë£¹ë³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í´ëŸ¬ìŠ¤í„°ê°€ í˜•ì„±ë©ë‹ˆë‹¤.\n",
    "- orangeëŠ” ìƒ‰ê¹”(color)ê³¼ ê³¼ì¼(fruit)ê·¸ë£¹ì˜ ì¤‘ê°„ì— ìœ„ì¹˜í•˜ë©°, ë™ìŒì´ì˜ì–´ í˜„ìƒì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "- appleì€ smartphoneê³¼ ê°€ê¹Œì´ ìˆìŠµë‹ˆë‹¤.\n",
    "- cookì€ ìŒì‹(food)ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ë“¤ê³¼ ì¸ì ‘í•´ ìˆìœ¼ë©°, ìš”ë¦¬ ë™ì‚¬ê°€ ìŒì‹ê³¼ ê°•í•˜ê²Œ ê´€ë ¨ì´ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word analogy task\n",
    "\n",
    "- Word analogy ë¬¸ì œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë‹¨ì–´ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ìœ ì¶”í•˜ëŠ” ê³¼ì œì…ë‹ˆë‹¤:  \n",
    "    \"*a* is to *b* as *c* is to **____**\". \n",
    "\n",
    "- ì˜ˆë¥¼ë“¤ì–´:  \n",
    "    *man* : *woman* = *king* : *queen*.\n",
    "\n",
    "### GloVe embedding and word analogy\n",
    "- ì‚¬ì „í•™ìŠµëœ GloVe ì„ë² ë”©ì—ì„œëŠ” ì´ëŸ¬í•œ ë‹¨ì–´ ê°„ ê´€ê³„ê°€ ë²¡í„° ê³µê°„ êµ¬ì¡° ì†ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚©ë‹ˆë‹¤.\n",
    "- ì¦‰, word embedding vector $\\mathbf{e}_a, \\mathbf{e}_b, \\mathbf{e}_c, \\mathbf{e}_d$ë“¤ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ë²¡í„° ì—°ì‚°ì´ ê·¼ì‚¬ì ìœ¼ë¡œ ì„±ë¦½í•©ë‹ˆë‹¤. :   \n",
    "    $$\\mathbf{e}_b - \\mathbf{e}_a + \\mathbf{e}_c \\approx \\mathbf{e}_d $$\n",
    "\n",
    "- ì´ ë²¡í„° ì—°ì‚°ì„ í†µí•´ analogyë¥¼ ë§Œì¡±í•˜ëŠ” ìƒˆë¡œìš´ ë‹¨ì–´ dë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì´ëŠ” GloVeì„ë² ë”©ì´ ë‹¨ìˆœíˆ <b>ê°œë³„ ë‹¨ì–´ì˜ ì˜ë¯¸</b>ë¿ ì•„ë‹ˆë¼ <b>ë‹¨ì–´ë“¤ ê°„ì˜ ê´€ê³„</b>ê¹Œì§€ í•™ìŠµí–ˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def word_analogy(word_a, word_b, word_c, glove, top_k = 5):\n",
    "    \"\"\" \n",
    "    Solve word analogy tasks using vector arithmetic:\n",
    "        word_b - word_a + word_c = ?\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    embedding_matrix = glove.vectors.to(device)  # [V, D]\n",
    "\n",
    "    vec_a = glove[word_a].to(device)\n",
    "    vec_b = glove[word_b].to(device)\n",
    "    vec_c = glove[word_c].to(device)\n",
    "\n",
    "    analogy_vector = vec_b - vec_a + vec_c\n",
    "\n",
    "    cosine_similarities = (embedding_matrix @ analogy_vector) / (embedding_matrix.norm(dim=1) * analogy_vector.norm() + 1e-8)  # [V]\n",
    "\n",
    "    # Get top-k most similar words\n",
    "    top_values, top_indices = torch.topk(cosine_similarities, top_k)\n",
    "\n",
    "    results = []\n",
    "    for idx, score in zip(top_indices.tolist(), top_values.tolist()):\n",
    "        candidate = glove.itos[idx]\n",
    "        if candidate in {word_a, word_b, word_c}:\n",
    "            continue\n",
    "        results.append((candidate, score))\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"king - man + woman â‰ˆ ?\")\n",
    "word_analogy(\"man\", \"king\", \"woman\", glove, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import TranslationDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” í”„ë‘ìŠ¤ì–´(French) ë¬¸ì¥ì„ ì…ë ¥ ë°›ì•„ ì˜ì–´(English) ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­í•˜ëŠ” ê¸°ê³„ ë²ˆì—­ ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ê³  í•™ìŠµí•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ êµ¬ì¡°ëŠ” [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ Seq2Seq (Sequence-to-Sequence) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "## Dataset\n",
    "ë²ˆì—­ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ `TranslationDataset`ì€ ê° ìƒ˜í”Œì„ íŠœí”Œ `(source_sentence, target_sentence)`í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- source_sentence : ë²ˆì—­ ëŒ€ìƒì´ ë˜ëŠ” í”„ë‘ìŠ¤ì–´ ë¬¸ì¥\n",
    "- target_sentence : ë²ˆì—­ íƒ€ê²Ÿì´ ë˜ëŠ” ì˜ì–´ ë¬¸ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(path_tsv = \"/datasets/NLP/eng-fra.txt\")\n",
    "\n",
    "test_size = int(0.1 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - test_size - valid_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\\n\")\n",
    "\n",
    "for source_sentence, target_sentence in train_dataset:\n",
    "    print(\"Example source sentence:\", source_sentence)\n",
    "    print(\"Example target sentence:\", target_sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy tokenizers\n",
    "í”„ë‘ìŠ¤ì–´ì™€ ì˜ì–´ ë¬¸ì¥ í† í°í™”ë¥¼ ìœ„í•´ì„œëŠ” `spaCy` ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì–¸ì–´ë³„ tokenizerë¥¼ í™œìš©í•©ë‹ˆë‹¤\n",
    "\n",
    "- `fr_core_news_sm`: í”„ë‘ìŠ¤ì–´ í† í°í™” ë° ê¸°ë³¸ ì–¸ì–´ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” spaCy ëª¨ë¸\n",
    "- `en_core_web_sm`: ì˜ì–´ í† í°í™” ë° ê¸°ë³¸ ì–¸ì–´ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” spaCy ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "tokenizer_french = get_tokenizer(lambda text: [tok.text.lower() for tok in spacy_fr.tokenizer(text)])\n",
    "tokenizer_english = get_tokenizer(lambda text: [tok.text.lower() for tok in spacy_en.tokenizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "text = \"This is an example sentence.\"\n",
    "tokenized_text = tokenizer_english(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "ê° ì–¸ì–´(í”„ë‘ìŠ¤ì–´, ì˜ì–´)ì— ëŒ€í•´ ì •ì˜ëœ tokenizerë¥¼ ì´ìš©í•˜ì—¬ `vocabulary`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹ìˆ˜ í† í°(special tokens)ìœ¼ë¡œëŠ” ë‹¤ìŒ 4ê°€ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    " - `<pad>` : ë¬¸ì¥ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•œ padding í† í°\n",
    " - `<unk>` : ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ (OOV; out-of-vocabulary)\n",
    " - `<sos>` : ë¬¸ì¥ì˜ ì‹œì‘ (Start of Sentence)\n",
    " - `<eos>` : ë¬¸ì¥ì˜ ë (End of Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "SOS_TOKEN = \"<sos>\"  # Start of Sentence\n",
    "EOS_TOKEN = \"<eos>\"  # End of Sentence\n",
    "\n",
    "SPECIAL_TOKENS = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN]\n",
    "\n",
    "source_token_list = [tokenizer_french(source) for source, _ in train_dataset]\n",
    "target_token_list = [tokenizer_english(target) for _, target in train_dataset]\n",
    "\n",
    "source_vocab = build_vocab_from_iterator(source_token_list, specials=SPECIAL_TOKENS, min_freq = 2)\n",
    "target_vocab = build_vocab_from_iterator(target_token_list, specials=SPECIAL_TOKENS, min_freq = 2)\n",
    "\n",
    "source_vocab.set_default_index(source_vocab[UNK_TOKEN])\n",
    "target_vocab.set_default_index(target_vocab[UNK_TOKEN])\n",
    "\n",
    "print(f\"Vocab sizes â†’ French: {len(source_vocab)}, English: {len(target_vocab)}\")\n",
    "\n",
    "print(\"Source vocab (French): \", source_vocab.get_itos()[:10])\n",
    "print(\"Target vocab (English): \", target_vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN_IDX  = source_vocab[PAD_TOKEN]\n",
    "SOS_TOKEN_IDX  = source_vocab[SOS_TOKEN]\n",
    "EOS_TOKEN_IDX  = source_vocab[EOS_TOKEN]\n",
    "assert PAD_TOKEN_IDX == target_vocab[PAD_TOKEN]\n",
    "assert SOS_TOKEN_IDX == target_vocab[SOS_TOKEN]\n",
    "assert EOS_TOKEN_IDX == target_vocab[EOS_TOKEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collate_batch\n",
    "<mark>ì‹¤ìŠµ</mark> `collate_seq2seq_batch`í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "- `source_sentence`(í”„ë‘ìŠ¤ì–´ ë¬¸ì¥)ì™€ `target_sentence`(ì˜ì–´ ë¬¸ì¥) ê°ê°ì— ëŒ€í•´ ë‹¤ìŒ ê³¼ì •ë“¤ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "  - <b>Tokenization</b> : ê° ë¬¸ì¥ì„ í•´ë‹¹ ì–¸ì–´ì˜ tokenizerë¥¼ ì´ìš©í•´ í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "    - `tokenizer_french`ì™€ `tokenizer_english`ë¥¼ ì´ìš©í•˜ì„¸ìš”\n",
    "  - <b>Vocabulary ë§¤í•‘</b>: ê° í† í°ì„ í•´ë‹¹ ì–¸ì–´ì˜ `Vocabulary`ë¥¼ ì´ìš©í•˜ì—¬ ì •ìˆ˜ ì¸ë±ìŠ¤(token indices)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "    - `source_vocab`ê³¼ `target_vocab`ì„ ì´ìš©í•˜ì„¸ìš”\n",
    "  - ë¬¸ì¥ì˜ ì‹œì‘ì—ëŠ” `<sos>`í† í°ì„, ë¬¸ì¥ì˜ ëì—ëŠ” `<eos>`í† í°ì„ ì¶”ê°€í•´ì¤ë‹ˆë‹¤.\n",
    "    - `SOS_TOKEN`, `EOS_TOKEN` ë˜ëŠ” `SOS_TOKEN_IDX`, `EOS_TOKEN_IDX`ë¥¼ ì´ìš©í•˜ì„¸ìš”.\n",
    "- <b>Padding</b>: [`torch.nn.utils.rnn.pad_sequence`](https://docs.pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html)í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ mini-batchë‚´ì˜ <b>ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ê¸¸ì´</b>ì— ë§ì¶° paddingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_seq2seq_batch(batch):\n",
    "    source_batch, target_batch = [], []\n",
    "    for source_sentence, target_sentence in batch:\n",
    "        source_indices = ...  # TODO\n",
    "        target_indices = ...  # TODO\n",
    "        source_batch.append(torch.tensor(source_indices, dtype=torch.long))\n",
    "        target_batch.append(torch.tensor(target_indices, dtype=torch.long))\n",
    "\n",
    "    # pad to max_length in batch\n",
    "    source_batch = torch.nn.utils.rnn.pad_sequence(source_batch, padding_value=PAD_TOKEN_IDX, batch_first=True)\n",
    "    target_batch = torch.nn.utils.rnn.pad_sequence(target_batch, padding_value=PAD_TOKEN_IDX, batch_first=True)\n",
    "    return source_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_seq2seq_batch)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_seq2seq_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_seq2seq_batch)\n",
    "\n",
    "for X, y in test_loader:\n",
    "    print(\"Mini-batch X shape:\", X.shape)\n",
    "    print(\"Mini-batch y shape:\", y.shape)\n",
    "    print(\"\\n1st source text:\", X[0])\n",
    "    print(\"1st target text:\", y[0])\n",
    "    break\n",
    "\n",
    "print(\"\\n<sos> token index:\", SOS_TOKEN_IDX)\n",
    "print(\"<eos> token index:\", EOS_TOKEN_IDX)\n",
    "print(\"<pad> token index:\", PAD_TOKEN_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "``` python\n",
    "Mini-batch X shape: torch.Size([64, 27])\n",
    "Mini-batch y shape: torch.Size([64, 23])\n",
    "\n",
    "1st source text: tensor([  2,  19, 241, 136,  47,   9,   1,   4,   3,   0,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
    "1st target text: tensor([  2,   8,  62, 117,  13,   1,   7,  20,   4,   3,   0,   0,   0,   0,\n",
    "          0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
    "\n",
    "<sos> token index: 2\n",
    "<eos> token index: 3\n",
    "<pad> token index: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Seq2Seq Model\n",
    "\n",
    "### Overview\n",
    "\n",
    "![](resources/seq2seq1.png)\n",
    "\n",
    "seq2seq ëª¨ë¸ì€ ì¸ì½”ë”(Encoder)ì™€ ë””ì½”ë”(Decoder) ë‘ ê°œì˜ ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. \n",
    " - Encoder (ì¸ì½”ë”): ë²ˆì—­í•  source ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìˆœí™˜ ì‹ ê²½ë§(RNN/LSTM/GRU)ì„ í†µí•´ ë¬¸ì¥ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ <b>context vector</b> $\\mathbf{z}$ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n",
    " - Decoder (ë””ì½”ë”) : Encoderì—ì„œ ìƒì„±ëœ context vectorë¥¼ ì…ë ¥ë°›ì•„, target ì–¸ì–´ ë¬¸ì¥ì„ í•œ ë‹¨ì–´ì”© ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "### Encoder\n",
    "\n",
    "ì…ë ¥ ì‹œí€€ìŠ¤ $X = (x_1, x_2, \\dots, x_{T_x})$ê°€ ì£¼ì–´ì¡Œì„ë•Œ, Encoder LSTMì€ ê° time-step $t$ì—ì„œ ì•„ë˜ ìˆ˜ì‹ì— ë”°ë¼ hidden stateì™€ cell stateë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "(\\mathbf{h}_t, \\mathbf{c}_t) = \\text{LSTM}_{\\text{enc}}(x_t, \\mathbf{h}_{t-1}, \\mathbf{c}_{t-1})\n",
    "$$\n",
    "\n",
    " - $(\\mathbf{h}_t, \\mathbf{c}_t)$ëŠ” ì§€ê¸ˆê¹Œì§€ ì…ë ¥ë°›ì€ í† í°ë“¤ $x_{1:t}$ì— ëŒ€í•œ ì •ë³´ë¥¼ ì••ì¶•í•˜ì—¬ ë‹´ê³  ìˆëŠ” ìƒíƒœ ë²¡í„°ì…ë‹ˆë‹¤.\n",
    " - ìµœì¢…ì ìœ¼ë¡œ ë¬¸ì¥ ì „ì²´ë¥¼ encodingí•˜ê³  ìˆëŠ” context vector $\\mathbf{z}$ëŠ” ë§ˆì§€ë§‰ ì‹œì  $T_x$ì—ì„œì˜ hidden stateì™€ cell stateë¡œ ì •ì˜ë©ë‹ˆë‹¤\n",
    "\n",
    "$$\\mathbf{z} = (\\mathbf{h}_{T_x}, \\mathbf{c}_{T_x})$$\n",
    "\n",
    "<mark>ì‹¤ìŠµ</mark> `Encoder` ëª¨ë“ˆì„ ì™„ì„±í•˜ì„¸ìš”\n",
    " - Embedding layer: `self.embedding`ë ˆì´ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì…ë ¥ í† í° ì¸ë±ìŠ¤ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    " - Droptout layer: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ `self.dropout`ë ˆì´ì–´ì— ì„ë² ë”© ë²¡í„°ë¥¼ í†µê³¼ì‹œí‚µë‹ˆë‹¤.\n",
    " - LSTM layer: `self.lstm`ë ˆì´ì–´ë¥¼ í†µê³¼ì‹œì¼œ context vectorë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "   - LSTM ë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ì„¸ ê°€ì§€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤ ([docs](https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html)):\n",
    "     - `output` : ë§ˆì§€ë§‰ LSTM layerì˜ ëª¨ë“  time-stepì—ì„œì˜ hidden state $(h_1, h_2, \\dots, h_{T_x})$\n",
    "     - `hidden` : ëª¨ë“  LSTM layerì˜ final hidden state $h_{T_x}$.\n",
    "     - `cell` : ëª¨ë“  LSTM layerì˜ final cell state $h_{T_x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, pad_token_index, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = pad_token_index)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor of shape (batch_size, src_len) containing token indices for the source sentence.\n",
    "\n",
    "        Returns:\n",
    "            (hidden, cell): Tuple of tensors containing the final hidden and cell states of all LSTM layers.\n",
    "        \"\"\"\n",
    "        \n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size = len(source_vocab), embed_dim = 128, hidden_dim = 256,\n",
    "                  num_layers = 2, pad_token_index = PAD_TOKEN_IDX, dropout = 0.5)\n",
    "\n",
    "X = torch.randint(0, 100, (8, 20))  # (batch_size, src_len)\n",
    "hidden, cell = encoder(X)\n",
    "\n",
    "print(\"Encoder hidden state shape:\", hidden.shape)  # (num_layers, batch_size, hidden_dim)\n",
    "print(\"Encoder cell state shape:\", cell.shape)      # (num_layers, batch_size, hidden_dim)\n",
    "\n",
    "assert hidden.shape == (2, 8, 256), f\"Expected hidden shape (2, 8, 256), but got {hidden.shape}\"\n",
    "assert cell.shape == (2, 8, 256), f\"Expected cell shape (2, 8, 256), but got {cell.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "DecoderëŠ” Encoderë¡œ ë¶€í„° ì „ë‹¬ë°›ì€ context vector $\\mathbf{z} = (\\mathbf{h}_{T_x}, \\mathbf{c}_{T_x})$ë¥¼ ì´ˆê¸° ìƒíƒœë¡œ í•˜ì—¬, ë²ˆì—­ ëŒ€ìƒì´ ë˜ëŠ” íƒ€ê²Ÿ ë¬¸ì¥ì„ í•œ ë‹¨ì–´ì”© ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤\n",
    "\n",
    "Docoder LSTMì˜ ì´ˆê¸° ìƒíƒœ $(\\mathbf{h}_0^d, \\mathbf{c}_0^d)$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ Encoder LSTMì˜ ë§ˆì§€ë§‰ stateë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.\n",
    "\n",
    "$$(\\mathbf{h}_0^d, \\mathbf{c}_0^d) = \\mathbf{z} = (\\mathbf{h}_{T_x}, \\mathbf{c}_{T_x})$$\n",
    "\n",
    "ì´í›„ Docoder LSTMì€ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ $Y = (y_1, y_2, \\dots, y_{T_y})$ì˜ ê° time-step $t$ì— ëŒ€í•˜ì—¬, ì•„ë˜ ìˆ˜ì‹ì— ë”°ë¼ hidden stateì™€ cell stateë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "(\\mathbf{h}_t^d, \\mathbf{c}_t^d) = \\text{LSTM}_{\\text{dec}}(y_t, \\mathbf{h}_{t-1}^d, \\mathbf{c}_{t-1}^d)\n",
    "$$\n",
    "\n",
    "ë˜í•œ DecoderëŠ” ê° time-step $t$ì—ì„œ ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥  ë¶„í¬(logits)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤:\n",
    "$$\\mathbf{\\hat{y}}_t = \\mathbf{W}_{hy}\\mathbf{h}_t^d + b_y, \\quad t=1,2,...,T_y$$\n",
    "\n",
    "<mark>ì‹¤ìŠµ</mark> `Decoder` ëª¨ë“ˆì„ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    " - `Decoder`ëŠ” í•œ time-stepì˜ ë””ì½”ë”©ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì¦‰ ì…ë ¥ í† í°ì˜ ê¸¸ì´(sequence length)ëŠ” í•­ìƒ `1`ì…ë‹ˆë‹¤. \n",
    " - `seq_length = 1`ì´ë¯€ë¡œ, í…ì„œì˜ ì°¨ì› ì²˜ë¦¬ì— ìœ ì˜í•˜ì„¸ìš”.\n",
    "   - í•„ìš”ì— ë”°ë¼ [`unsqueeze`](https://docs.pytorch.org/docs/main/generated/torch.unsqueeze.html)ì™€ [`squeeze`](https://docs.pytorch.org/docs/main/generated/torch.squeeze.html)ë©”ì„œë“œë¥¼ í™œìš©í•˜ì—¬ í…ì„œì˜ ì°¨ì›ì„ ì ì ˆíˆ ë³€í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "ê³„ì‚° ê³¼ì •\n",
    " - Embedding layer: `self.embedding`ë ˆì´ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì…ë ¥ í† í° ì¸ë±ìŠ¤ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    " - Droptout layer: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ `self.dropout`ë ˆì´ì–´ì— ì„ë² ë”© ë²¡í„°ë¥¼ í†µê³¼ì‹œí‚µë‹ˆë‹¤.\n",
    " - LSTM layer: dropoutì„ í†µê³¼í•œ ì„ë² ë”© ë²¡í„°ì™€ previous hidden/cell statesë¥¼ `self.lstm`ë ˆì´ì–´ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "   - LSTM layerì˜ ì¶œë ¥ê°’ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤\n",
    "     - `output` : ë§ˆì§€ë§‰ LSTM layerì˜ hidden state $h_t^d$\n",
    "     - `hidden` : New hidden state  $\\mathbf{h}_t^d$.\n",
    "     - `cell` : New cell state $\\mathbf{c}_t^d$.\n",
    " - fully-connected layer: LSTMì˜ ì¶œë ¥ `output`ë¥¼ `self.fc_out`ë ˆì´ì–´ì— ì „ë‹¬í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ì˜ ì˜ˆì¸¡ê°’(`logits`)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, pad_token_index, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = pad_token_index)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_token, hidden, cell):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_token: Tensor of shape (batch_size,) containing token index for the current time step.\n",
    "            hidden: Previous hidden states of the decoder LSTM (or the encoder's final hidden state).\n",
    "            cell: Previous cell states of the decoder LSTM (or the encoder's final cell state).\n",
    "\n",
    "        Returns:\n",
    "            logits: Tensor of shape (batch_size, vocab_size) containing prediction scores for the next token.\n",
    "            (hidden, cell): Updated hidden and cell states.\n",
    "        \"\"\"\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "        \n",
    "        return logits, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "dec = Decoder(vocab_size = len(target_vocab), embed_dim = 128, hidden_dim = 256,\n",
    "              num_layers = 2, pad_token_index = PAD_TOKEN_IDX, dropout = 0.5)\n",
    "\n",
    "input_token = torch.randint(0, 100, (8,))  # (batch_size,)\n",
    "logits, (hidden, cell) = dec(input_token, hidden, cell)\n",
    "\n",
    "print(\"Decoder logits shape:\", logits.shape)        # (batch_size, vocab_size)\n",
    "print(\"Decoder hidden state shape:\", hidden.shape)  # (num_layers, batch_size, hidden_dim)\n",
    "print(\"Decoder cell state shape:\", cell.shape)      # (num_layers, batch_size, hidden_dim)\n",
    "\n",
    "assert logits.shape == (8, len(target_vocab)), f\"Expected logits shape (8, {len(target_vocab)}), but got {logits.shape}\"\n",
    "assert hidden.shape == (2, 8, 256), f\"Expected hidden shape (2, 8, 256), but got {hidden.shape}\"\n",
    "assert cell.shape == (2, 8, 256), f\"Expected cell shape (2, 8, 256), but got {cell.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ ì•ì„œ êµ¬í˜„í•œ `Encoder`ì™€ `Decoder`ë¥¼ ê²°í•©í•˜ì—¬ `Seq2Seq` ëª¨ë¸ì„ ì™„ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "<mark>ê³¼ì œ</mark> ì•„ë˜ ì„¤ëª…ì„ ì°¸ê³ í•˜ì—¬ `Seq2Seq`ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    "- `src`: ì…ë ¥ ì‹œí€€ìŠ¤ $X = (x_1, x_2, \\dots, x_{T_x})$\n",
    "- `tgt`: íƒ€ê²Ÿ ì‹œí€€ìŠ¤ $Y = (y_1, y_2, \\dots, y_{T_y})$\n",
    "\n",
    "Forward ê³¼ì •:\n",
    "1. ì˜ˆì¸¡ê°’ $\\hat{y}_t \\ (t = 1, 2, \\dots, T_y)$ë¥¼ ì €ì¥í•  `output_logits`í…ì„œë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤., \n",
    "2. <b>Encoding</b>: ì…ë ¥ ë¬¸ì¥ `src`ë¥¼ `encoder`ì— ì „ë‹¬í•˜ì—¬ context vector (final hidden state & cell state)ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "3. For each iteration of the decoding:\n",
    "   - `decoder`ì— í˜„ì¬ ì…ë ¥ $y_t$ì™€ ì´ì „ hidden state $\\mathbf{h}_{t-1}^d$, ê·¸ë¦¬ê³  ì´ì „ cell states $\\mathbf{c}_{t-1}^d$ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "      - ì²«ë²ˆì§¸ iterationì—ì„œëŠ” `encoder`ì˜ final state $(\\mathbf{h}_{T_x}, \\mathbf{c}_{T_x})$ê°€ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
    "   - `decoder`ë¡œë¶€í„° ì˜ˆì¸¡ê°’ $\\hat{y}_{t+1}$ì™€ ìƒˆë¡œìš´ hidden/cell state $(\\mathbf{h}_{t}^d, \\mathbf{c}_{t}^d)$ë¥¼ ë°˜í™˜ë°›ìŠµë‹ˆë‹¤.\n",
    "   - ì˜ˆì¸¡ê°’ $\\hat{y}_{t+1}$ë¥¼ `output_logits`í…ì„œì˜ $t$ ìœ„ì¹˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "   - ë‚œìˆ˜ë¥¼ ë°œìƒì‹œì¼œ \"teacher force\"ì„ ì ìš©í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "      - \"teacher force\"ì„ ì ìš©í•  ê²½ìš°, ë‹¤ìŒ ì…ë ¥ í† í°ì€ ground-truth $y_{t+1}$ì…ë‹ˆë‹¤.\n",
    "      - \"teacher force\"ì„ ì ìš©í•˜ì§€ ì•Šì„ ê²½ìš°, ë‹¤ìŒ ì…ë ¥ í† í°ì€ `decoder`ì˜ ì˜ˆì¸¡ê°’ $\\arg\\max(\\hat{y}_{t+1})$ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_vocab_size = self.decoder.fc_out.out_features\n",
    "        \n",
    "    def forward(self, src, tgt, teacher_forcing_prob = 0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor of shape (batch_size, source_seq_len) containing token indices for the source sentences.\n",
    "            tgt: Tensor of shape (batch_size, target_seq_len) containing token indices for the target sentences.\n",
    "            teacher_forcing_prob: Probability of using the ground-truth token as the next input.\n",
    "\n",
    "        Returns:\n",
    "            output_logits: Tensor of shape (batch_size, target_seq_len, target_vocab_size)\n",
    "        \"\"\"\n",
    "        batch_size, target_seq_len = tgt.shape\n",
    "        output_logits = torch.zeros(batch_size, target_seq_len, self.target_vocab_size).to(tgt.device)\n",
    "\n",
    "        # Encode source sequence\n",
    "        (hidden, cell) = ...  # TODO\n",
    "\n",
    "        # First decoder input is <sos>\n",
    "        current_input_token = tgt[:, 0]  # (batch_size,)\n",
    "\n",
    "        # Decode one step at at time\n",
    "        for t in range(1, target_seq_len):\n",
    "            decoder_logits, (hidden, cell) = ...  # TODO\n",
    "            output_logits[:, t, :] = ...  # TODO\n",
    "\n",
    "            # choose next input token: teacher forcing or modelâ€™s own prediction\n",
    "            use_teacher_forcing = torch.rand(1).item() < teacher_forcing_prob\n",
    "            predicted_token  = decoder_logits.argmax(dim = 1)  # (batch_size,)\n",
    "            current_input_token = tgt[:, t] if use_teacher_forcing else predicted_token\n",
    "\n",
    "        return output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "\n",
    "enc = Encoder(vocab_size = len(source_vocab), embed_dim = embed_dim, hidden_dim = hidden_dim,\n",
    "              num_layers = num_layers, pad_token_index = PAD_TOKEN_IDX, dropout = 0.5)\n",
    "\n",
    "dec = Decoder(vocab_size = len(target_vocab), embed_dim = embed_dim, hidden_dim = hidden_dim,\n",
    "              num_layers = num_layers, pad_token_index = PAD_TOKEN_IDX, dropout = 0.5)\n",
    "\n",
    "model = Seq2Seq(enc, dec)\n",
    "\n",
    "\n",
    "X = torch.randint(0, 100, (32, 20)) # (batch_size, src_len)\n",
    "y = torch.randint(0, 100, (32, 30)) # (batch_size, tgt_len)\n",
    "\n",
    "logits = model(X, y, teacher_forcing_prob=0.5)\n",
    "print(\"Seq2Seq logits shape:\", logits.shape)  # (batch_size, tgt_len, target_vocab_size)\n",
    "\n",
    "assert logits.shape == (32, 30, len(target_vocab)), f\"Expected logits shape (32, 30, {len(target_vocab)}), but got {logits.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "í•™ìŠµ ë£¨í”„ëŠ” ì „í˜•ì ì¸ ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì •ê³¼ ê±°ì˜ ë™ì¼í•˜ë‚˜, ë‹¤ìŒê³¼ ê°™ì€ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- Loss ê³„ì‚°ì—ì„œ `<sos>` ì œì™¸: `<sos>` í† í°ì—ëŠ” ëŒ€ì‘ë˜ëŠ” ì˜ˆì¸¡ê°’ì´ ì—†ìœ¼ë¯€ë¡œ, Lossë¥¼ ê³„ì‚°í•˜ê¸° ì „ `tgt` í…ì„œì™€ `output` í…ì„œì˜ ì²«ë²ˆì§¸ ì»¬ëŸ¼ì„ ì˜ë¼ëƒ…ë‹ˆë‹¤\n",
    "- lossê³„ì‚°ì„ ìœ„í•´ `output` í…ì„œì˜ shapeì„ `(batch_size, tgt_len, vocab_size)`ì—ì„œ `(batch_size * tgt_len, vocab_size)`ìœ¼ë¡œ reshapeí•©ë‹ˆë‹¤.\n",
    "- `clip_grad_norm_`í•¨ìˆ˜ë¥¼ í†µí•´ gradient clippingì„ ìˆ˜í–‰í•˜ì—¬ gradient explosionì„ ë°©ì§€í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, dataloader, criterion, optimizer, epoch, clip = 1.0):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for src, tgt in tqdm(dataloader, desc=f'Training Epoch {epoch + 1}', total = len(dataloader), leave=False):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        output = model(src, tgt) # (batch_size, tgt_len, vocab_size)\n",
    "\n",
    "        # exclude first token (<sos>) from loss, flatten\n",
    "        output_dim = output.shape[-1]\n",
    "        output_flat = output[:, 1:].reshape(-1, output_dim)\n",
    "        tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output_flat, tgt_flat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Loop\n",
    " - í‰ê°€ ë‹¨ê³„ì—ì„œëŠ” teacher forcingì„ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \n",
    " - ì¦‰, ëª¨ë¸ì€ ì •ë‹µ í† í°ì„ ì°¸ì¡°í•˜ì§€ ì•Šê³ , ì˜¤ì§ <b>ìì‹ ì´ ìƒì„±í•œ ì´ì „ ì˜ˆì¸¡ê°’ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬</b> ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ <b>Autoregressive generation</b>ì´ë¼ê³  í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(model, device, dataloader, criterion, epoch = 0):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(dataloader, desc='Validation/Test', total = len(dataloader), leave=False):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt, teacher_forcing_prob=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output_flat = output[:, 1:].reshape(-1, output_dim)\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output_flat, tgt_flat)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>ì‹¤ìŠµ</mark> ì§ì ‘ Seq2Seq ë²ˆì—­ ëª¨ë¸ì„ í•™ìŠµí•´ë³´ì„¸ìš”.\n",
    " - í•™ìŠµì—ëŠ” <u>ì•½ 20ë¶„</u> ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.\n",
    " - Loss functionìœ¼ë¡œëŠ” `CrossEntropyLoss`ë¥¼ ì‚¬ìš©í•˜ë©°, `ignore_index = PAD_TOKEN_IDX`ìœ¼ë¡œ ì„¸íŒ…í•´ì¤ë‹ˆë‹¤.\n",
    "   - ì´ë¥¼ í†µí•´, loss ê³„ì‚° ì‹œ `<pad>` í† í°ì— ëŒ€ì‘ë˜ëŠ” ì˜ˆì¸¡ê°’ë“¤ì€ ëª¨ë‘ ë¬´ì‹œë˜ì–´ í•™ìŠµì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    SOURCE_VOCAB_SIZE  = len(source_vocab)\n",
    "    TARGET_VOCAB_SIZE  = len(target_vocab)\n",
    "    embed_dim       = 256\n",
    "    hidden_dim      = 512\n",
    "    num_layers      = 2\n",
    "    encoder_dropout = 0.2\n",
    "    decoder_dropout = 0.2\n",
    "    grad_clip       = 1.0\n",
    "\n",
    "    num_epochs    = 7\n",
    "    batch_size = 64\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              shuffle=True, num_workers= 4, collate_fn=collate_seq2seq_batch)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                              shuffle=False, num_workers= 4, collate_fn=collate_seq2seq_batch)\n",
    "    test_dataloader  = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                              shuffle=False, num_workers= 4, collate_fn=collate_seq2seq_batch)\n",
    "\n",
    "    enc = Encoder(vocab_size = SOURCE_VOCAB_SIZE, embed_dim = embed_dim, hidden_dim = hidden_dim,\n",
    "                num_layers = num_layers, pad_token_index = PAD_TOKEN_IDX, dropout = encoder_dropout)\n",
    "    dec = Decoder(vocab_size = TARGET_VOCAB_SIZE, embed_dim = embed_dim, hidden_dim = hidden_dim,\n",
    "                num_layers = num_layers, pad_token_index = PAD_TOKEN_IDX, dropout = decoder_dropout)\n",
    "    model = Seq2Seq(enc, dec).to(device)\n",
    "\n",
    "    print(f'The model has {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_IDX)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_one_epoch(model, device, train_dataloader, criterion, optimizer, epoch, grad_clip)\n",
    "        val_loss = evaluate_one_epoch(model, device, val_dataloader, criterion, epoch)\n",
    "        print(f\"Epoch {epoch + 1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {val_loss:.3f}\")\n",
    "        print(f'\\t | Train PPL: {math.exp(train_loss):7.3f} | Val. PPL: {math.exp(val_loss):7.3f}')\n",
    "\n",
    "    test_loss = evaluate_one_epoch(model, device, test_dataloader, criterion)\n",
    "    print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model = train_seq2seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive sentence translation\n",
    "\n",
    "ì´ì œ í•™ìŠµëœ Seq2Seq ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë¬¸ì¥ì„ ë²ˆì—­í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë²ˆì—­ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "1. ë²ˆì—­í•  ì…ë ¥ ë¬¸ì¥ì„ `encoder`ì— ì „ë‹¬í•˜ì—¬ context vector `(hidden, cell)`ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "2. `decoder`ì˜ ì²«ë²ˆì§¸ ì…ë ¥ tokenì„ `<sos>`ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "3. ì˜ˆì¸¡ëœ í† í°ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬, `<eos>` í† í°ì„ ë§Œë‚ ë•Œê¹Œì§€ ë°˜ë³µì ìœ¼ë¡œ next token predictionì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, max_len = 50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    tokens = [SOS_TOKEN] + tokenizer_french(sentence) + [EOS_TOKEN]\n",
    "    source_indices = torch.tensor(source_vocab(tokens), dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        (hidden, cell) = model.encoder(source_indices)\n",
    "\n",
    "        input_tok = torch.tensor([SOS_TOKEN_IDX], device=device)\n",
    "        result_tokens = []\n",
    "        for _ in range(max_len):\n",
    "            pred, (hidden, cell) = model.decoder(input_tok, hidden, cell)\n",
    "            next_token_idx = pred.argmax(1).item()\n",
    "            if next_token_idx == EOS_TOKEN_IDX:\n",
    "                break\n",
    "            result_tokens.append(target_vocab.lookup_token(next_token_idx))\n",
    "            input_tok = torch.tensor([next_token_idx], device=device)\n",
    "\n",
    "    return result_tokens\n",
    "\n",
    "example_sentences = [\n",
    "    \"Je t'aime.\",\n",
    "    \"Je me sens heureux\"\n",
    "]\n",
    "\n",
    "for example_fr in example_sentences:\n",
    "    print(f\"FR â¡ï¸ EN  : '{example_fr}'\")\n",
    "    print(f\"Predicted: {translate_sentence(example_fr, model)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pretrained Word Embeddings\n",
    "\n",
    "<mark>optional ì‹¤ìŠµ</mark> ì‚¬ì „ í•™ìŠµëœ GloVe ì„ë² ë”©(Pretrained Embedding) í™œìš©í•˜ì—¬ `SentimentClassifier` ëª¨ë¸ì„ í•™ìŠµí•´ë³´ê³ , ê¸°ì¡´ í•™ìŠµ ë°©ì‹ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ì„¸ìš”\n",
    "\n",
    "- ë³¸ ì‹¤ìŠµì€ ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤. \n",
    "- <mark>ì£¼ì˜</mark> ì¶”ê°€ ì‹¤ìŠµì„ ì‹œì‘í•˜ê¸° ì „ì—, ì§€ê¸ˆê¹Œì§€ ì™„ë£Œí•œ ê³¼ì œ ì½”ë“œë¥¼ `git push`í•˜ì—¬ ê³¼ì œ ì±„ì ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def build_embedding_layer_from_glove(glove, vocabulary):\n",
    "    \"\"\"\n",
    "    Create a PyTorch nn.Embedding layer with weights initialized from pre-trained GloVe embeddings.\n",
    "\n",
    "    Args:\n",
    "        glove: Pre-trained GloVe embeddings.\n",
    "        vocabulary: List of words in your vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch nn.Embedding layer with pre-loaded weights.\n",
    "    \"\"\"\n",
    "    embedding_dim = glove.dim\n",
    "    vocab_size = len(vocabulary)\n",
    "    weights = torch.zeros(vocab_size, embedding_dim)\n",
    "\n",
    "    for idx, word in enumerate(vocabulary):\n",
    "        weights[idx] = glove[word]\n",
    "\n",
    "    # Setting freeze=True prevents the weights from being updated during training.\n",
    "    embedding_layer = nn.Embedding.from_pretrained(weights, freeze=True)\n",
    "    return embedding_layer\n",
    "\n",
    "glove = GloVe(name=\"6B\", dim=50, cache=\"/datasets/NLP/glove\")\n",
    "\n",
    "custom_vocabulary = glove.stoi.keys() # replace with your own vocabulary\n",
    "embedding_layer = build_embedding_layer_from_glove(glove, custom_vocabulary)\n",
    "\n",
    "print(\"vocabulary size:\", len(custom_vocabulary))\n",
    "print(\"Embedding layer weights.shape : \", embedding_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
