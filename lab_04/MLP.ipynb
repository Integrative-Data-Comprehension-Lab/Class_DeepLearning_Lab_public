{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch에서는 데이터를 효율적으로 관리하고 모델에 전달하기 위해 `Dataset` 과 `DataLoader` 를 사용합니다\n",
    "\n",
    "## Dataset 클래스\n",
    "``torch.utils.data.Dataset``는 데이터셋을 정의할때 사용하는 추상 클래스(abstract class)입니다.\n",
    "\n",
    "<b>사용자 정의 데이터셋 (Custom dataset)</b>을 정의하려면 이 클래스를 상속하고 다음 세 가지 메서드를 override해야 합니다:\n",
    "\n",
    "- `__init__` : 생성자\n",
    "- `__len__`을 구현하여 `len(dataset)` 호출 시 데이터셋의 크기 (전체 샘플 수)를 반환하도록 합니다.\n",
    "- `__getitem__` 을 구현하여 `dataset[i]` 호출 시 `i`번째 샘플 `(input, target)`을 반환하도록 합니다.\n",
    "\n",
    "아래는 텐서 `X` 와 `y`로 부터 사용자 정의 데이터셋 클래스 `CustomDatasetExample`를 만드는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetExample(Dataset):\n",
    "    def __init__ (self , X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        assert len(X) == len(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data_x = torch.rand([10, 3], dtype=torch.float32) #example tensor dataset with 3 feature and 10 examples\n",
    "data_y = torch.arange(10) # target y\n",
    "\n",
    "example_dataset = CustomDatasetExample(data_x, data_y)\n",
    "print(f\"len(dataset): {len(example_dataset)}\")\n",
    "print(f\"4-th example: {example_dataset[3]}\\n\")\n",
    "for X, y in example_dataset:\n",
    "    print(f\"X: {X},\\ty: {y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>실습</mark> `CustomImageDataset`을 완성하세요\n",
    "\n",
    "CSV파일(`metadata.csv`)로 부터 이미지 경로(`image_path`)와 라벨(`label`: cat or dog)정보를 읽어 `(image, target)` 튜플을 반환하는 `CustomImageDataset`을 구현해봅니다\n",
    "\n",
    "- `__init__`\n",
    "  - `root_dir`: 이미지와 CSV파일이 저장된 경로입니다\n",
    "  - `metadata_filename` : 메타데이터(라벨 및 이미지 경로)가 저장된 CSV 파일 이름입니다.\n",
    "- `__len__` : 데이터셋의 크기 (전체 샘플 수)를 반환합니다\n",
    "- `__getitem__` : `idx`번째 example `(image, target)`을 반환합니다\n",
    "  - `self.root_dir`과 CSV파일의 \"image_path\" 컬럼의 값을 이용하여 이미지 경로를 얻을 수 있습니다.\n",
    "  - `image`는 이미지를 [`PIL.Image.open`](https://pillow.readthedocs.io/en/stable/reference/Image.html) 함수를 이용해 불러온 뒤 반환합니다.\n",
    "  - `target`은 문자열(\"cat\", \"dog\")을 정수(`0`, `1`)로 매핑하여 반환합니다. `self.class_to_idx` 딕셔너리를 사용하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pd.read_csv('resources/cat_dog_images/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, metadata_filename, transform=None, target_transform=None):\n",
    "        self.metadata_df = pd.read_csv(os.path.join(root_dir, metadata_filename))\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        class_names = self.metadata_df[\"label\"].drop_duplicates().sort_values().tolist()\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        ##### YOUR CODE START #####  \n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ##### YOUR CODE START #####  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "custom_dataset = CustomImageDataset(root_dir = 'resources/cat_dog_images', \n",
    "                                   metadata_filename = \"metadata.csv\",\n",
    "                                   transform = transform)\n",
    "\n",
    "for i in range(len(custom_dataset)):\n",
    "    image, target = custom_dataset[i]\n",
    "    print(f\"{i+1}-th example: X.shape = {image.shape}, label = {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "읽어온 이미지 (PIL object)를 `torch.tensor`로 변환하기 위해서는 [`torchvision.transforms.ToTensor()`](https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html)를 이용할 수 있습니다.\n",
    "\n",
    "이 함수는 `PIL Image` 또는 `numpy.ndarray` 객체를 `torch.FloatTensor`로 변환해줍니다\n",
    "- 변환된 텐서는 `(C, H, W)`의 shape을 가집니다.\n",
    "- 변환된 텐서는 `[0.0, 1.0]`사이의 값을 가집니다.\n",
    "\n",
    "`transforms.ToTensor()`의 `__call__` 메직메서드를 호출하며 PIL image를 전달하면 결과값을 텐서로 반환받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "image = Image.open(\"resources/cat_dog_images/images_001/dog-01.jpg\")\n",
    "print(\"type(image): \", type(image))\n",
    "\n",
    "image_tensor = transforms.ToTensor()(image)\n",
    "print(\"image_tensor.shape: \", image_tensor.shape)\n",
    "print(\"\\nimage_tensor: \", image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, cols=8, rows=5):\n",
    "    figure = plt.figure(figsize=(12, 6))\n",
    "    for i in range(len(dataset)):\n",
    "        img, label = dataset[i]\n",
    "        figure.add_subplot(rows, cols, i+1)\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.numpy().transpose((1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_samples(custom_dataset, rows = 2 , cols = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "`DataLoader`는 `Dataset`을 배치 단위(mini-batch) 묶어주며, `shuffle`, 병렬 처리(`num_workers`) 등을 지원합니다\n",
    "\n",
    "하지만 우리가 정의한 `CustomImageDataset`은 모든 샘플의 이미지 크기가 같지 않기 때문에 아래와 같이 dataloader를 이용해 mini-batch로 쌓으려고 하면 오류가 생깁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset= custom_dataset, batch_size=6, shuffle=True, num_workers=1)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(X.shape, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CustomImageDataset`에서 이미지들을 고정된 사이즈로 resize한 뒤 리턴함으로써 이 문제를 해결할 수 있습니다. 이를 위해 `transforms.Resize()`를 `transform`에 추가해 줍니다.\n",
    "- [`transforms.Resize()`](https://pytorch.org/vision/main/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize)는 이미지를 주어진 크기로 resize해줍니다.\n",
    "\n",
    "이 외에도 `torchvision.transforms`에 다양한 이미지 전처리 함수가 구현되어있으며, 자세한 내용은 [docs](https://pytorch.org/vision/main/transforms.html)을 참고하기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "custom_datset_train = CustomImageDataset(root_dir = 'resources/cat_dog_images', \n",
    "                                         metadata_filename = \"metadata.csv\",\n",
    "                                         transform = train_transform)\n",
    "\n",
    "visualize_samples(custom_datset_train, rows = 2 , cols = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset = custom_datset_train, batch_size=4, shuffle=True, num_workers=1)\n",
    "print(\"--- First iteration ---\")\n",
    "for X, y in train_dataloader:\n",
    "    print(\"X.shape: \", X.shape, \"\\ty:\", y)\n",
    "\n",
    "print(\"\\n--- Second iteration ---\")\n",
    "for X, y in train_dataloader:   # shuffle = True이므로 매번 다른 순서로 example들을 가져옵니다.\n",
    "    print(\"X.shape: \", X.shape, \"\\ty:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffle = True`이므로 DataLoader를 순회할 때 마다 이미지 순서가 뒤바뀌는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron (MLP) with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from planar_utils import plot_decision_boundary, load_planar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X, y = load_planar_dataset()\n",
    "print(f\"X.shape = {X.shape}, y.shape = {y.shape}\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 \"꽃 모양(flower shape)\" 데이터를 분류하는 모델을 구현해 보겠습니다.\n",
    "- `X`: `m = 400`개의 example과 `d = 2`개의 feature를 가진 입력 데이터. Shape = `(400, 2)` \n",
    "- `y`: target (0 = red, 1 = blue)\n",
    "\n",
    "## 1st trial: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegressionCV(); # Train the logistic regression classifier\n",
    "clf.fit(X, y.flatten())\n",
    "\n",
    "# Plot the decision boundary for logistic regression\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, y)\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "# Print accuracy\n",
    "y_pred = clf.predict(X)\n",
    "accuracy = np.mean(y_pred == y.squeeze()) * 100\n",
    "print(f\"Accuracy of logistic regression: {accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 같이 로지스틱 회귀 또는 선형 모델은 데이터를 선형으로만 나눌 수 었이 좋은 성능을 기대하기 어렵습니다.\n",
    "- MLP 신경망은 비선형을 학습할 수 있기 때문에 더 좋은 성능을 기대할 수 있습니다!\n",
    "\n",
    "## 2-layer Multi-layer Perceptron\n",
    "<div style=\"background-color: white; width: fit-content; padding: 10px;\">\n",
    "    <img src=\"resources/MLP_2-layer.png\" style=\"width:400px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "**Notation 정리**:\n",
    "- 위첨자 $[l]$ : $l$번째 layer를 표현\n",
    "- 위첨자 $(i)$ : $i$번째 샘플(example)을 표현 (예: $x^{(i)}$ 는 $i^{th}$ training example을 의미)\n",
    "- 아래첨자 $i$ : 벡터의 $i$ 번째 원소 (예: $a^{[1]}_i$은 $\\mathbf{a}^{[1]}$의 $i$번째 원소).\n",
    "\n",
    "\n",
    "### Forward pass\n",
    "입력 벡터 $ \\mathbf{x} \\in \\mathbb{R}^{d} $ 가 주어졌을때, forward pass는 아래와 같이 주어집니다.\n",
    "$$\n",
    "\\mathbf{z}^{[1]} = \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} \\in \\mathbb{R}^{h}\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{a}^{[1]} = \\mathrm{ReLU}(\\mathbf{z}^{[1]})\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{z}^{[2]} = \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + \\mathbf{b}^{[2]} \\in \\mathbb{R}^{C}\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = \\mathbf{a}^{[2]} = \\mathrm{softmax}(\\mathbf{z}^{[2]})\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $d$: 입력 차원 수 (`in_dim`)\n",
    "- $h$: 은닉층의 뉴런 수 (`hidden_dim`)\n",
    "- $C$: 출력 클래스 수 (`out_dim`)\n",
    "- $ \\mathbf{W}^{[1]} \\in \\mathbb{R}^{h \\times d} $, $ \\mathbf{b}^{[1]} \\in \\mathbb{R}^{h} $: weights and bias for layer 1  \n",
    "- $ \\mathbf{W}^{[2]} \\in \\mathbb{R}^{C \\times h} $, $ \\mathbf{b}^{[2]} \\in \\mathbb{R}^{C} $: weights and bias for layer 2\n",
    "\n",
    "\n",
    "\n",
    "### Activations functions\n",
    "비선형성을 도입하기 위해 각 은닉층 뒤에 ReLU 함수를 적용합니다.\n",
    "\n",
    "<img src=\"resources/activation_functions.png\" style=\"width:500px;\">\n",
    "\n",
    "<mark>실습</mark> 위의 forawd pass를 참고하여, 은닉층이 1개인 `TwoLayerMLP`를 완성하세요\n",
    "- [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "- [`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html): 비선형 활성화 함수(Non-linear activations)입니다. 선형 변환 후에 적용하여 모델에 **비선형성**을 부여하며, 이를 통해 신명망이 복잡한 함수와 데이터 분포를 학습할수 있도록 도와줍니다.\n",
    "- `softmax`는 적용하지 마세요. (`nn.CrossEntropyLoss()`는 내부적으로 softmax와 cross-entropy를 동시에 처리해줍니다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TwoLayerMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ##### YOUR CODE START #####  \n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 Forward pass를 수행하려면, 초기화된 `model` 객체에 input data를 `()` 연산자를 통해 전달하면 됩니다. 이때 `nn.Module`에 정의된 `__call__` 매직메서드가 호출되며, 이 메서드는 역전파를 위한 필요한 연산들과 함께 `forward`를 호출해줍니다.\n",
    "\n",
    "직접 ``model.forward()``를 호출하지 마세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model = TwoLayerMLP(in_dim = 10, hidden_dim = 20, out_dim = 2)  # initalize model\n",
    "print(model)\n",
    "\n",
    "X = torch.rand(16, 10) # dummy data with batch_size = 16\n",
    "logits = model(X)\n",
    "print(f\"\\nX.shape = {X.shape}, logits.shape = {logits.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"[Parameters] {name}\\t| Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 출력 `logits` 값은 각 클래스에 대한 <b>비정규화된 점수(un-normalized scores)</b>를 나타냅니다.\n",
    "\n",
    "`logits`값으로 부터 예측된 클래스 인덱스 `y_pred`를 계산하기 위해서는 아래와 같이 `nn.Softmax`와 `argmax`를 이용할 수 있습니다.\n",
    "\n",
    "이때 `nn.Softmax`를 이용한 확률 계산은 loss를 계산하거나 확률 분포를 얻을때에는 필요하지만, 단순히 가장 가능성이 높은 클래스를 선택하는 데에는 필수적이지 않으므로 생략할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# logits has shape (batch_size, num_classes)\n",
    "pred_prob = nn.Softmax(dim = 1)(logits) # Predicted probability for each class\n",
    "print(f\"Predicted probabilities (shape = {pred_prob.shape}):\\n\", pred_prob)\n",
    "\n",
    "y_pred = pred_prob.argmax(axis = 1)\n",
    "print(f\"\\nPredicted classes: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "다중 클래스 분류에서 가장 널리 사용되는 Categorical Cross-Entropy Loss를 사용합니다.\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{C} y_j^{(i)} \\log \\left( \\hat{y}_j^{(i)} \\right)\n",
    "\\tag{5}\n",
    "$$\n",
    "- $m$ : 전체 학습 데이터 수 (Number of training examples)\n",
    "- $C$ : 클래스 개수\n",
    "- $ \\mathbf{y}^{(i)} \\in \\{0, 1\\}^C$: $i$번째 샘플의 one-hot encoded true label\n",
    "- $ \\hat{\\mathbf{y}}^{(i)} \\in [0, 1]^C $ : softmax를 통해 계산된 predicted probability vector\n",
    "\n",
    "`loss.backward()`를 호출하면 자동으로 모든 학습 가능한 파라미터들에 대한 손실함수의 미분이 계산됩니다: \n",
    "$$\\frac{\\partial{\\mathcal{L}}}{\\partial{\\mathbf{W}^{[1]}}}, \n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{\\mathbf{b}^{[1]}}}, \n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{\\mathbf{W}^{[2]}}}, \n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{\\mathbf{b}^{[2]}}}$$\n",
    "\n",
    "<mark>실습</mark> 아래 함수 `train_flower_main`를 잘 읽어보고 딥러닝 학습의 전체 흐름을 다시 한번 복습해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def train_flower_main(hidden_dim, learning_rate, num_epochs):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the dataset\n",
    "    X_np, y_np = load_planar_dataset()\n",
    "    X_tensor = torch.from_numpy(X_np).float().to(device)           # shape: (m, d)\n",
    "    y_tensor = torch.from_numpy(y_np).long().squeeze().to(device)  # shape: (m)\n",
    "    \n",
    "    # Initialize the model\n",
    "    in_dim = X_tensor.shape[1]          # Number of features\n",
    "    out_dim = len(y_tensor.unique())    # binary classification\n",
    "    model = TwoLayerMLP(in_dim, hidden_dim, out_dim).to(device)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        logits = model(X_tensor)\n",
    "        loss = criterion(logits, y_tensor)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 1000 == 0: # Print loss every 1000 epochs\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_pred = predict(model, X_tensor, device = device)\n",
    "    accuracy = (y_pred == y_tensor).float().mean().item() * 100\n",
    "    print(f'Training Accuracy : {accuracy:.2f}%')\n",
    "\n",
    "    # Plot decision boundary\n",
    "    plot_decision_boundary(lambda x: predict(model, x).cpu().numpy(), X_np, y_np.squeeze())\n",
    "    plt.title(f\"Decision Boundary for MLP with {hidden_dim} hidden units\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict(model, X, device = \"cpu\"):\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X_tensor = torch.from_numpy(X).float().to(device)\n",
    "        else:\n",
    "            X_tensor = X.to(device)\n",
    "\n",
    "        logits = model(X_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>실습</mark> 은닉층 크기에 따른 모델 성능\n",
    "- 다양한 `hidden_dim` 값(1, 2, 4, 8, ...)에 대해 모델을 학습시키고, 결정 경계(Decision Boundary)의 형태와 학습 정확도(Training Accuracy)의 변화를 관찰해보세요\n",
    "- `Training Accuracy > 87%`를 달성해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_flower_main(hidden_dim = 1, learning_rate = 0.1, num_epochs = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 해석\n",
    "- 은닉 유닛 수(`hidden_dim`)가 많아질수록 모델의 <b>표현력(복잡도)</b>이 올라가며, 더 복잡한 형태의 결정 경계를 학습할 수 있습니다.\n",
    "- 하지만 모델이 너무 크면, 훈련 데이터에 과도하게 맞추는 과적합(overfitting) 현상이 발생합니다. 이 경우, 모델은 훈련 데이터에는 성능이 높지만 새로운 데이터(test set)에 대해서는 오히려 성능이 저하됩니다. \n",
    "- 이는 모델이 훈련 데이터의 **유의미한 패턴뿐만 아니라 노이즈까지 암기**해버렸기 때문입니다. 즉, 데이터를 일반화(generalize)해서 이해하지 못하고 **암기(memoriziation)**를 중심으로 학습된 상태라고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with MLP\n",
    "이번에는 다층 퍼셉트론(MLP)을 활용하여 <b>이미지 분류(Image Classification)</b>를 수행해봅니다.  \n",
    "\n",
    "여기서는 은닉층이 2개인 **3-Layer MLP**를 구성합니다.\n",
    "\n",
    "## Forward Pass 구성\n",
    "\n",
    "1. Flatten: 3차원 입력 이미지 (1, 28, 28)를 크기가 $ d = 1 \\times 28 \\times 28 = 784$인 1차원 텐서로 변환합니다.\n",
    "\n",
    "2. Layer 1 (Input → Hidden1)\n",
    "    $$\n",
    "    \\mathbf{z}^{[1]} = \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} \\in \\mathbb{R}^{h_1}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\mathbf{a}^{[1]} = \\mathrm{ReLU}(\\mathbf{z}^{[1]})\n",
    "    $$\n",
    "\n",
    "   - $d$: 입력 차원 수 (`in_dim`)\n",
    "   - $h_1$: 첫번째 은닉층의 뉴런 수\n",
    "   - $\\mathbf{W}^{[1]} \\in \\mathbb{R}^{h_1 \\times d}$, $\\mathbf{b}^{[1]} \\in \\mathbb{R}^{h_1}$: weights and bias for layer 1  \n",
    "\n",
    "\n",
    "3. Layer 2 (Hidden1 → Hidden2)\n",
    "    $$\n",
    "    \\mathbf{z}^{[2]} = \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + \\mathbf{b}^{[2]} \\in \\mathbb{R}^{h_2}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\mathbf{a}^{[2]} = \\mathrm{ReLU}(\\mathbf{z}^{[2]})\n",
    "    $$\n",
    "    - $h_2$: 두번째 은닉층의 뉴런 수\n",
    "    - $\\mathbf{W}^{[2]} \\in \\mathbb{R}^{h_2 \\times h_1}$, $\\mathbf{b}^{[2]} \\in \\mathbb{R}^{h_2}$: weights and bias for layer 2\n",
    "\n",
    "4. Layer 3 (Hidden2 → Output)\n",
    "\n",
    "    $$\n",
    "    \\mathbf{z}^{[3]} = \\mathbf{W}^{[3]} \\mathbf{a}^{[2]} + \\mathbf{b}^{[3]} \\in \\mathbb{R}^{C}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\hat{\\mathbf{y}} = \\mathbf{a}^{[3]} = \\mathrm{softmax}(\\mathbf{z}^{[3]})\n",
    "    $$\n",
    "\n",
    "    where:\n",
    "    - $C$: 출력 클래스 수 (`out_dim`)\n",
    "    - $\\mathbf{W}^{[3]} \\in \\mathbb{R}^{C \\times h_2}$, $\\mathbf{b}^{[3]} \\in \\mathbb{R}^{C}$: weights and bias for layer 3\n",
    "\n",
    "## Parameter, input and output shapes\n",
    "Batch size를 $B$라고 했을때,\n",
    "| Layer             | Input Shape     | Weight Shape        | Bias Shape     | Output Shape    |\n",
    "|------------------|------------------|----------------------|----------------|------------------|\n",
    "| Flatten           | $(B, 1, 28, 28)$ | -                    | -              | $(B, 784)$         |\n",
    "| Layer 1           | $(B, 784)$         | $(h_1, 784)$            | $(h_1,)$          | $(B, h_1)$          |\n",
    "| Layer 2           | $(B, h_1)$          |$(h_2, h_1)$             | $(h_2,)$          | $(B, h_2)$          |\n",
    "| Layer 3           | $(B, h_2)$          | $(C, h_2)$              | $(C,)$           | $(B, C)$           |\n",
    "\n",
    "참고: batch 처리를 위해 PyTorch에서는 아래와 같은 수식에 따라 계산됩니다.\n",
    "```python\n",
    "z1 = x @ W1.T + b1  # x: (B, d), W1: (h1, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>실습</mark> MultiLayerPerceptron\n",
    "위 수식을 만족하는 3-layer MLP 모델 `MultiLayerPerceptron`을 완성하세요.\n",
    "- 여기서 $h_1 = h_2 = $`hidden_dim` 입니다\n",
    "- [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html): 순서가 있는 모듈들의 컨테이너(container)로, 데이터는 컨테이너 내의 모든 모듈들을 정의된것과 같은 순서로 통과합니다.\n",
    "- [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
    "- [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "- [`nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### YOUR CODE START #####  \n",
    "        # Use nn.Sequential() to stack layers together.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model = MultiLayerPerceptron(in_dim = 1*28*28, hidden_dim = 512, out_dim = 10)\n",
    "print(model)\n",
    "\n",
    "X = torch.rand(16, 1, 28, 28) # dummy data for testing with batch_size 16\n",
    "logits = model(X) \n",
    "\n",
    "print(\"\\nlogits.shape: \", logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>실습</mark> 앞서 정의한 `model = MultiLayerPerceptron(in_dim = 28*28, hidden_dim = 512, out_dim = 10)`의 파라미터 수를 직접 손으로 계산하여 숫자로 기입해보세요 (숫자 계산식으로 입력해도 괜찮으나 파이썬 변수를 사용하지 마세요)\n",
    "\n",
    " - Weight $\\mathbf{W}^{[1]}$의 파라미터 수는 얼마인가요?\n",
    " - Bias $\\mathbf{b}^{[1]}$의 파라미터 수는 얼마인가요?\n",
    " - Weight $\\mathbf{W}^{[2]}$의 파라미터 수는 얼마인가요?\n",
    " - Bias $\\mathbf{b}^{[2]}$의 파라미터 수는 얼마인가요?\n",
    " - Weight $\\mathbf{W}^{[3]}$의 파라미터 수는 얼마인가요?\n",
    " - Bias $\\mathbf{b}^{[3]}$의 파라미터 수는 얼마인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params_W1 = ...  # TODO: number of parameters in W1\n",
    "num_params_b1 = ...  # TODO: number of parameters in b1\n",
    "num_params_W2 = ...  # TODO: number of parameters in W2\n",
    "num_params_b2 = ...  # TODO: number of parameters in b2\n",
    "num_params_W3 = ...  # TODO: number of parameters in W3\n",
    "num_params_b3 = ...  # TODO: number of parameters in b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "assert sum(p.numel() for p in model.parameters() if p.requires_grad) == (num_params_W1 + num_params_b1 + num_params_W2 + num_params_b2 + num_params_W3 + num_params_b3), \"❌ 계산한 파라미터 수가 실제 모델과 일치하지 않습니다.\"\n",
    "print('\\033[92mAll tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WandB로 학습 추적하기\n",
    "\n",
    "딥러닝 모델을 학습할 때, 손실값(loss)이나 정확도(accuracy) 등의 지표를 일일이 `list`로 저장하고 관리하는 것은 매우 번거로운 작업입니다.\n",
    "\n",
    "앞으로는 이러한 지표들을 WandB라는 도구를 통해 자동으로 기록하고 시각화하겠습니다.\n",
    "\n",
    "WandB를 사용하면 실험 결과를 웹 브라우저에서 직관적으로 확인하고, 여러 실험 결과들 손쉽게 비교할 수 있습니다.\n",
    "\n",
    "<img src=\"resources/WandB.png\" style=\"width:800px;\">\n",
    "\n",
    "<mark>실습</mark> [WandB](https://kr.wandb.ai/)에 회원가입을 한 후, 터미널(terminal)에서 다음 명령어를 통해 로그인하세요\n",
    "\n",
    "```bash\n",
    "$ wandb login YOUR_API_KEY\n",
    "```\n",
    "\n",
    "`YOUR_API_KEY`는 회원가입 후 발급받은 개인 API 키를 입력합니다.\n",
    "\n",
    "\n",
    "## Training an MLP Model with WandB\n",
    "아래 함수들은 지난 실습에서 작성한 학습코드를 다음의 측면에서 보다 효율적이고 확장 가능하게 개선한 것입니다:\n",
    "- `tqdm`을 이용학 학습 진행 상황 및 시간 추적\n",
    "- `save_checkpoint`와 `load_checkpoint`를 이용하여 모델을 저장하고 불러오는 기능 추가\n",
    "- `AverageMeter` 클래스를 통한 성능 지표의 누적 평균 계산\n",
    "- `config` 객체를 함수 외부에서 전달하여 하이퍼파라미터 튜닝을 유연하게 수행\n",
    "\n",
    "<mark>실습</mark> 아래 코드들을 자세히 리뷰해보고, 적절한 위치에 wandb 로그 기능들을 추가해주세요. 다음의 metric들을 WandB에서 추적할 것입니다.\n",
    " - `epoch`\n",
    " - `Train Loss`\n",
    " - `Train Accuracy`\n",
    " - `Test Loss`\n",
    " - `Test Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MNIST_datasets(data_root_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=data_root_dir, train=True, download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=data_root_dir, train=False, download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def create_dataloaders(train_dataset, test_dataset, device, batch_size, num_worker):\n",
    "    kwargs = {}\n",
    "    if device.startswith(\"cuda\"):\n",
    "        kwargs.update({\n",
    "            'pin_memory': True,\n",
    "        })\n",
    "\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size=batch_size, \n",
    "                                  shuffle=True, num_workers=num_worker, **kwargs)\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size, \n",
    "                                 shuffle=False, num_workers=num_worker, **kwargs)\n",
    "    \n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_one_epoch` 함수와 `evaluate_one_epoch`함수를 수정하여 아래의 지표들을 **WandB를 통해 추적**하세요:\n",
    " - `epoch`\n",
    " - `Train Loss`\n",
    " - `Train Accuracy`\n",
    " - `Test Loss`\n",
    " - `Test Accuracy`\n",
    "\n",
    "WandB에 지표를 기록하려면 다음과 같은 형태로 `wandb.log()` 함수를 사용하세요:\n",
    "\n",
    "```python\n",
    "wandb.log({\n",
    "    \"지표1 이름\": 값1,\n",
    "    \"지표2 이름\": 값2,\n",
    "    ...\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, dataloader, criterion, optimizer, epoch):\n",
    "    \"\"\" train for one epoch \"\"\"\n",
    "    loss_meter = AverageMeter('Loss', '.4e')\n",
    "    accuracy_meter = AverageMeter('Accuracy', '6.2f')\n",
    "    data_time = AverageMeter('Data_Time', '6.3f') # Time for data loading\n",
    "    batch_time = AverageMeter('Batch_Time', '6.3f') # time for mini-batch train\n",
    "    metrics_list = [loss_meter, accuracy_meter, data_time, batch_time, ]\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f'Training Epoch {epoch + 1}', total=len(dataloader))\n",
    "    for images, target in progress_bar:\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        accuracy = compute_accuracy(output, target)\n",
    "        loss_meter.update(loss.item(), images.shape[0])\n",
    "        accuracy_meter.update(accuracy, images.shape[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        progress_bar.set_postfix(avg_metrics = \", \".join([str(x) for x in metrics_list]))\n",
    "        end = time.time()\n",
    "    progress_bar.close()\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "    # wandb log variables: epoch, loss_meter.avg, accuracy_meter.avg with names \"epoch\", \"Train Loss\", \"Train Accuracy\"\n",
    "\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "\n",
    "def evaluate_one_epoch(model, device, dataloader, criterion, epoch = 0, use_wandb = True):\n",
    "    loss_meter = AverageMeter('Loss', '.4e')\n",
    "    accuracy_meter = AverageMeter('Accuracy', '6.2f')\n",
    "    metrics_list = [loss_meter, accuracy_meter]\n",
    "\n",
    "    model.eval() # switch to evaluate mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc='Validation/Test', total=len(dataloader))\n",
    "        for images, target in progress_bar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            accuracy = compute_accuracy(output, target)\n",
    "            loss_meter.update(loss.item(), images.shape[0])\n",
    "            accuracy_meter.update(accuracy, images.shape[0])\n",
    "\n",
    "            progress_bar.set_postfix(avg_metrics = \", \".join([str(x) for x in metrics_list]))\n",
    "        progress_bar.close()\n",
    "\n",
    "    if use_wandb:\n",
    "        ##### YOUR CODE START #####\n",
    "        # wandb log variables: epoch, loss_meter.avg, accuracy_meter.avg with names \"epoch\", \"Test Loss\", \"Test Accuracy\"\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    return accuracy_meter.avg\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Tracks and updates the running average of a metric.\"\"\"\n",
    "    def __init__(self, metric_name , format_spec = '.4f'):\n",
    "        self.metric_name = metric_name \n",
    "        self.format_spec = format_spec\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.metric_name}: {format(self.avg, self.format_spec)} (n={self.count})\"\n",
    "    \n",
    "\n",
    "def compute_accuracy(output, target):\n",
    "    \"\"\"\n",
    "    Computes the top-1 classification accuracy .\n",
    "\n",
    "    Args:\n",
    "        output (torch.Tensor): Model outputs (logits or probabilities), shape (batch_size, num_classes)\n",
    "        target (torch.Tensor): Ground truth labels, shape (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = output.argmax(dim=1)\n",
    "        accuracy = (pred == target).float().mean().item() * 100.0\n",
    "    return accuracy   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_model` 함수의 시작과 끝에 각각 `wandb.init()`과 `wandb.finish()`를 적절히 추가하여, 학습 과정의 주요 지표들을 WandB를 통해 추적할 수 있도록 설정하세요.\n",
    "\n",
    "- `wandb.init()`은 실험을 시작하며 프로젝트 이름, 실험 이름, hyperparameter 등 다양한 설정(config)을 전달합니다.\n",
    "- `wandb.finish()`는 실험을 종료하고 로그를 정리합니다.\n",
    "- `wandb.init()`와 `wandb.finish()` 사이에 `wandb.log()`를 추가하여 학습 손실과 정확도 등의 다양한 지표들을 손쉽게 기록할 수 있습니다.\n",
    "\n",
    "\n",
    "예시:\n",
    "``` python\n",
    "wandb.init(\n",
    "    project = \"YOUR_PROJECT_NAME\",\n",
    "    name = \"YOUR_EXPERIMENT_NAME\",\n",
    "    config = {\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"MLP\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"epochs\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # your training and evaluation code\n",
    "    wandb.log({\"loss\": loss, \"accuracy\": accuracy})\n",
    "\n",
    "wandb.finish()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" 전체 학습 및 평과를 위한 최상위 진입점(main entry point) \"\"\"\n",
    "\n",
    "    config = {\n",
    "        \"mode\": \"train\",  # Options: \"train\", \"eval\"\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "        ## data and preprocessing settings\n",
    "        \"data_root_dir\": '/datasets',\n",
    "        \"num_workers\": 4,\n",
    "\n",
    "        ## Training Hyperparams\n",
    "        \"batch_size\": 128,\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"num_epochs\": 20,\n",
    "\n",
    "        ## checkpoints\n",
    "        \"checkpoint_path\": \"checkpoints/checkpoint.pth\",    # Path to save the most recent checkpoint\n",
    "        \"best_model_path\": \"checkpoints/best_model.pth\",    # Path to save the best model checkpoint\n",
    "        \"checkpoint_save_interval\": 10,                     # Save a checkpoint every N epochs\n",
    "        \"resume_training\": None,    # Options: \"latest\", \"best\", or None\n",
    "\n",
    "        ## WandB logging\n",
    "        \"wandb_project_name\": \"MNIST-experiments\",\n",
    "        \"wandb_experiment_name\" : \"MLP_L3_H512\",\n",
    "        \"model_architecture\": \"MLP\",\n",
    "        \"dataset_name\": \"MNIST\"\n",
    "    }\n",
    "\n",
    "    ## Model architecture hyperparameters\n",
    "    in_dim = 28*28\n",
    "    hidden_dim = 512\n",
    "\n",
    "    train_dataset, test_dataset = load_MNIST_datasets(config[\"data_root_dir\"])\n",
    "    num_classes = len(train_dataset.classes)\n",
    "\n",
    "    model = MultiLayerPerceptron(in_dim=in_dim, hidden_dim=hidden_dim, out_dim=num_classes)\n",
    "\n",
    "    print(f\"Using {config['device']} device\")\n",
    "\n",
    "    if config[\"mode\"] == \"train\":\n",
    "        train_model(model, train_dataset, test_dataset, config)\n",
    "    elif config[\"mode\"] == \"eval\":\n",
    "        load_and_evaluate_model(model, test_dataset, config)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {config['mode']}\")\n",
    "\n",
    "\n",
    "def train_model(model, train_dataset, test_dataset, config):\n",
    "    device = config[\"device\"]\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "    # Initialize WandB experiment\n",
    "    #  - 프로젝트 이름(project)은 config[\"wandb_project_name\"]에서 가져옵니다.\n",
    "    #  - 실험 이름(name)은 config[\"wandb_experiment_name\"]에서 가져옵니다.\n",
    "    #  - 실험 설정(config)은 config 전체를 그대로 전달합니다.\n",
    "\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "\n",
    "    train_dataloader, test_dataloader = create_dataloaders(train_dataset, test_dataset, device, \n",
    "                                                           batch_size = config[\"batch_size\"], \n",
    "                                                           num_worker = config[\"num_workers\"])\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config[\"learning_rate\"])\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    if config[\"resume_training\"]:\n",
    "        load_checkpoint_path = config[\"best_model_path\"] if config[\"resume_training\"] == \"best\" else config[\"checkpoint_path\"]\n",
    "        start_epoch, best_accuracy = load_checkpoint(load_checkpoint_path, model, optimizer, device)\n",
    "\n",
    "    for epoch in range(start_epoch, config[\"num_epochs\"]):\n",
    "        train_one_epoch(model, device, train_dataloader, criterion, optimizer, epoch)\n",
    "        test_accuracy = evaluate_one_epoch(model, device, test_dataloader, criterion, epoch)\n",
    "\n",
    "        ## save checkpoint\n",
    "        if (epoch + 1) % config[\"checkpoint_save_interval\"] == 0 or (epoch + 1) == config[\"num_epochs\"]: \n",
    "            is_best = test_accuracy > best_accuracy\n",
    "            best_accuracy = max(test_accuracy, best_accuracy)\n",
    "            save_checkpoint(config[\"checkpoint_path\"], model, optimizer, epoch, best_accuracy, is_best, config[\"best_model_path\"])\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "    # WandB 실험을 종료합니다.\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "\n",
    "    return best_accuracy\n",
    "\n",
    "\n",
    "def save_checkpoint(filepath, model, optimizer, epoch, best_accurcay, is_best, best_model_path):\n",
    "    save_dir = os.path.split(filepath)[0]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch + 1,\n",
    "        'best_accurcay': best_accurcay,\n",
    "    }\n",
    "    \n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, best_model_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer, device):\n",
    "    if os.path.isfile(filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_accurcay = checkpoint['best_accurcay']\n",
    "        print(f\"=> loaded checkpoint '{filepath}' (epoch {start_epoch})\")\n",
    "        return start_epoch, best_accurcay\n",
    "    else:\n",
    "        print(f\"=> no checkpoint found at '{filepath}'\")\n",
    "        return 0, 0\n",
    "    \n",
    "\n",
    "def load_and_evaluate_model(model, test_dataset, config):\n",
    "    \"\"\" Load model checkpoint from config[\"best_model_path\"] and evaulate the model \"\"\"\n",
    "\n",
    "    device = config[\"device\"]\n",
    "\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size=config[\"batch_size\"], \n",
    "                                  shuffle=False, num_workers=config[\"num_workers\"])\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config[\"learning_rate\"])  # Dummy optimizer to satisfy checkpoint loader\n",
    "    _, _ = load_checkpoint(config[\"best_model_path\"], model, optimizer, device)\n",
    "\n",
    "    test_accuracy = evaluate_one_epoch(model, device, test_dataloader, criterion, use_wandb = False)\n",
    "    print(f\"Test-set Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 수행한 뒤 W&B 홈페이지를 통해 결과를 살펴보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>실습</mark> `.gitignore` 파일 수정\n",
    "\n",
    "위 코드를 따라 학습을 진행하면 다음과 같은 폴더들이 자동으로 생성됩니다:\n",
    "\n",
    "1. `wandb/`: WandB를 통해 실험을 추적하면, 로그 파일과 메타데이터가 이 폴더에 저장됩니다.\n",
    "\n",
    "2. `checkpoints/` : 학습 도중 저장되는 모델 체크포인트 파일들이 이 폴더에 저장됩니다.\n",
    "\n",
    "이 두 폴더는 용량이 크고 변경내용 추적이 불필요하기 때문에 **GitHub 저장소에 업로드할 필요가 없습니다.**\n",
    "\n",
    "`.gitignore` 파일을 적절히 수정하여 `wandb/`폴더와 `checkpoints/`가 git 추적 대상에서 제외되도록 설정하세요.\n",
    "\n",
    "<mark>주의</mark> 수정이 완료된 `.gitignore`파일도 함께 `git push`하는 것을 잊지 마세요\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "(참고) shell 환경변수를 설정하여 wandb를 끌수도 있습니다.\n",
    "\n",
    "```python\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BetterMLP\n",
    "<mark>실습</mark> 이미지 분류 정확도를 높이기 위해 더 나은 MLP모델 `BetterMLP`를 설계해보세요. \n",
    "\n",
    "주어진 `BetterMLP` 클래스의 네트워크 구조를 자유롭게 구성하여, **test accuracy를 최대한 향상**시키는 것이 목표입니다.\n",
    "\n",
    " - Convolutional Layer나 `torchvision.models`의 사전학습(pre-trained) 모델을 사용하는 것은 <u>허용되지 않습니다<u>\n",
    " - 오직 Multi-layer Perceptron (MLP) 구조만을 이용하여 `test set accuracy > 95.0%`를 달성하세요\n",
    " - 해당 정확도를 달성한 모델의 <mark>checkpoint 파일을 github에 함께 push하세요</mark>. (아래 코드에 따라 `submitted_checkpoints/` 폴더에 checkpoint가 저장됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### YOUR CODE START #####  \n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model = BetterMLP(in_dim = 1*28*28, out_dim = 10)\n",
    "print(model)\n",
    "\n",
    "X = torch.rand(16, 1, 28, 28) # dummy data for testing with batch_size 16\n",
    "logits = model(X) \n",
    "\n",
    "print(\"\\nlogits.shape: \", logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>주의</mark> `main_BetterMLP()`함수와 `config` 값을 수정하는것은 <u>허용되지 않습니다</u>\n",
    "\n",
    "즉 batch_size, learning_rate, num_epochs 등과 같은 학습 관련 하이퍼파라미터 튜닝을 수행하지 <u>않고<u> 오직 모델 구조(`BetterMLP`) 만 변경하여 최고의 성능을 달성해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"mode\": \"train\",  # Options: \"train\", \"eval\"\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "    ## data and preprocessing settings\n",
    "    \"data_root_dir\": '/datasets',\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    ## Training Hyperparams\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"num_epochs\": 20,\n",
    "\n",
    "    ## checkpoints\n",
    "    \"checkpoint_path\": \"submitted_checkpoints/checkpoint.pth\",    # Path to save the most recent checkpoint\n",
    "    \"best_model_path\": \"submitted_checkpoints/best_model.pth\",    # Path to save the best model checkpoint\n",
    "    \"checkpoint_save_interval\": 10,                     # Save a checkpoint every N epochs\n",
    "    \"resume_training\": None,    # Options: \"latest\", \"best\", or None\n",
    "\n",
    "    ## WandB logging\n",
    "    \"wandb_project_name\": \"MNIST-experiments\",\n",
    "    \"wandb_experiment_name\" : \"BetterMLP\",\n",
    "    \"model_architecture\": \"MLP\",\n",
    "    \"dataset_name\": \"MNIST\"\n",
    "}\n",
    "\n",
    "def main_BetterMLP(config):\n",
    "    train_dataset, test_dataset = load_MNIST_datasets(config[\"data_root_dir\"])\n",
    "    num_classes = len(train_dataset.classes)\n",
    "\n",
    "    model = BetterMLP(in_dim=1*28*28, out_dim=num_classes)\n",
    "\n",
    "    print(f\"Using {config['device']} device\")\n",
    "\n",
    "    if config[\"mode\"] == \"train\":\n",
    "        test_accuracy = train_model(model, train_dataset, test_dataset, config)\n",
    "    elif config[\"mode\"] == \"eval\":\n",
    "        test_accuracy = load_and_evaluate_model(model, test_dataset, config)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {config['mode']}\")\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "main_BetterMLP(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>주의</mark> 실습 과제를 제출하기 전 아래 코드를 통해 저장된 checkpoint가 `test set accuracy > 95.0%`의 성능을 달성했는지 다시한번 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "config[\"mode\"] = \"eval\"\n",
    "main_BetterMLP(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
